{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "import scrubadub\n",
    "from pathlib import Path\n",
    "from pii_detection import LLM\n",
    "import json\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.metrics import fbeta_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T15:58:52.378340600Z",
     "start_time": "2024-02-11T15:58:28.036498400Z"
    }
   },
   "id": "f0975b7e95c60222",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c162a705195e434f84c501b58718c621"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\guybilitski\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "llm = LLM.LlmModel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:00:23.930316300Z",
     "start_time": "2024-02-11T15:58:52.380334500Z"
    }
   },
   "id": "6b113cb5008edf53",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "email_pattern = r\"\"\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\"\"\"\n",
    "def is_email(input_token):\n",
    "    if re.fullmatch(email_pattern, input_token):\n",
    "        return True\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:26:58.627601100Z",
     "start_time": "2024-02-11T16:26:58.604436600Z"
    }
   },
   "id": "a8fbaa5e0babd7b4",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# This is currently detecting all the urls. receiving recall of 0.5. We need to think how to say that a url is personal!\n",
    "url_pattern = r\"\\b(?:(?:https?:?//(?:www\\.)?|www\\.)[A-Za-z\\d][a-zA-Z\\d\\-\\.]{0,255}(?:\\.[a-zA-Z-]{2,6})?(?:/[\\w\\-\\.?&%=]{1,500}){0,10})\\b\"\n",
    "def is_url(input_token):\n",
    "    if re.fullmatch(url_pattern, input_token):\n",
    "        return True\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:27:00.339608500Z",
     "start_time": "2024-02-11T16:27:00.309407200Z"
    }
   },
   "id": "e8fae64e90b0b777",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def is_name(input_token, was_first_name=False):\n",
    "    if input_token[0].isupper() and input_token not in ['It', 'This', 'I']:\n",
    "        if llm.query_ner(input_token):\n",
    "            if was_first_name:\n",
    "                return 'I-NAME_STUDENT'\n",
    "            return 'B-NAME_STUDENT'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:32:35.547269Z",
     "start_time": "2024-02-11T16:32:35.532318300Z"
    }
   },
   "id": "f0f782f9d23aafac",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "working_directory = str(Path.cwd().parent)\n",
    "if working_directory not in sys.path:\n",
    "    sys.path.append(str(working_directory))"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:27:03.518792100Z",
     "start_time": "2024-02-11T16:27:03.493874800Z"
    }
   },
   "id": "initial_id",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('../data/raw/train.json') as f:\n",
    "    data = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:27:06.270782700Z",
     "start_time": "2024-02-11T16:27:05.319908900Z"
    }
   },
   "id": "9fdf9bcddb742f0c",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict(input_token, was_first_name=False):\n",
    "    # if is_email(input_token):\n",
    "    #     return 'B-EMAIL'\n",
    "    # if is_url(input_token):\n",
    "    #     return 'B-URL_PERSONAL'\n",
    "    naming = is_name(input_token, was_first_name) \n",
    "    if naming is not None:\n",
    "        return naming\n",
    "    return 'O'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:32:33.677191500Z",
     "start_time": "2024-02-11T16:32:33.652199500Z"
    }
   },
   "id": "6fb539dcd8f0c6fe",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waseem Mabunda  591 Smith Centers Apt. 656\n",
      "Joshuamouth, RI 95963 ( The Netherlands)  410.526.1667  vpi@mn.nl\n",
      "\n",
      "Mind Mapping,      Challenge:     For several years I have been working for an Asset manager in the Netherlands. During this period I have been involved in many  projects. Certainly in the world of asset management, much has changed in recent years in the area of Law and Regulations.  What I mainly experience in these projects is that all departments have a different interest in starting a new project. This  certainly does not benefit the project. How do you get everyone to complete a project in the common interest and how do you  motivate everyone who participate in the project?    Selection:    An improvement project can be approached in different ways. The most common way is the scrum approach. We work in  multidisciplinary teams that work in short sprints, with a fixed length of 1 to 4 weeks. Cooperation is very important and  everyone must be able to respond quickly to changing circumstances. Scrum is based on the theory of empirical process  control, or empiricism. Empiricism assumes that knowledge arises from experience and making decisions based on what is  known.     I chose mind mapping because I am looking for a way to show the creativity colleagues always have at the start of a project,  to  keep this up to date and very important to keep it visible.   But also with the thoughts to keep colleagues motivated and to show how their creativity contributes to the project.    So I want to see if scrum can be combined with Design Thinking and especially with Mind mapping.    Application:    When starting a new project at work, I checked whether it is workable to combine the scrum approach with Mind Mapping. The  central theme was to increase the STP (Straight through processing) rate for a specific product that we trade with an x  percentage.    As a scrum team, we have tried to provide insight into the various topics related to the 'increase STP rate' via a paper diagram.  Each team member could indicate in this diagram his or her creativity which related to increasing the STP rate.    After this we went to see if there was a connection between certain ideas. We quickly learned that certain ideas could be  combined and that certain steps in the project could be skipped. By combining scrum work and mind mapping, we were able to  go live with implementation faster and increase STP speed step by step.    By making the project visible through a diagram, colleagues also indicated that this gave them more energy to participate in the  project.\n",
      "\n",
      "D e s i g n  T h i n k i n g\n",
      "\n",
      "Insight:    The insight I got to combine scrum with mind mapping (Design thinking) is that if you make everyone's creativity and thinking  visible through Mind mapping, you will come sooner to a solid solution to complete a project. The feedback we received is that  it also gives more energy to colleagues who have participated in this project.     The biggest challenge was to create support for this new way of working.     At the beginning of the project, we showed a short video of how mind mapping works. This gave us immediate support from  our fellow team members to combine scrum with mind mapping.      https://www.youtube.com/watch?v=tIBN9VJ0S4a    The conclusion is that you definitely can combine scrum and Design thinking.    Approach:    In terms of approach, I wouldn't be much different from what I did in this project. I only see advantages of combining scrum  with mind mapping. As described in the alinia insight, there are only benefits.\n",
      "\n",
      "\n",
      "Smith\n",
      "Waseem Mabunda  591 Smith Centers Apt. 656\n",
      "Joshuamouth, RI 95963 ( The Netherlands)  410.526.1667  vpi@mn.nl\n",
      "\n",
      "Mind Mapping,      Challenge:     For several years I have been working for an Asset manager in the Netherlands. During this period I have been involved in many  projects. Certainly in the world of asset management, much has changed in recent years in the area of Law and Regulations.  What I mainly experience in these projects is that all departments have a different interest in starting a new project. This  certainly does not benefit the project. How do you get everyone to complete a project in the common interest and how do you  motivate everyone who participate in the project?    Selection:    An improvement project can be approached in different ways. The most common way is the scrum approach. We work in  multidisciplinary teams that work in short sprints, with a fixed length of 1 to 4 weeks. Cooperation is very important and  everyone must be able to respond quickly to changing circumstances. Scrum is based on the theory of empirical process  control, or empiricism. Empiricism assumes that knowledge arises from experience and making decisions based on what is  known.     I chose mind mapping because I am looking for a way to show the creativity colleagues always have at the start of a project,  to  keep this up to date and very important to keep it visible.   But also with the thoughts to keep colleagues motivated and to show how their creativity contributes to the project.    So I want to see if scrum can be combined with Design Thinking and especially with Mind mapping.    Application:    When starting a new project at work, I checked whether it is workable to combine the scrum approach with Mind Mapping. The  central theme was to increase the STP (Straight through processing) rate for a specific product that we trade with an x  percentage.    As a scrum team, we have tried to provide insight into the various topics related to the 'increase STP rate' via a paper diagram.  Each team member could indicate in this diagram his or her creativity which related to increasing the STP rate.    After this we went to see if there was a connection between certain ideas. We quickly learned that certain ideas could be  combined and that certain steps in the project could be skipped. By combining scrum work and mind mapping, we were able to  go live with implementation faster and increase STP speed step by step.    By making the project visible through a diagram, colleagues also indicated that this gave them more energy to participate in the  project.\n",
      "\n",
      "D e s i g n  T h i n k i n g\n",
      "\n",
      "Insight:    The insight I got to combine scrum with mind mapping (Design thinking) is that if you make everyone's creativity and thinking  visible through Mind mapping, you will come sooner to a solid solution to complete a project. The feedback we received is that  it also gives more energy to colleagues who have participated in this project.     The biggest challenge was to create support for this new way of working.     At the beginning of the project, we showed a short video of how mind mapping works. This gave us immediate support from  our fellow team members to combine scrum with mind mapping.      https://www.youtube.com/watch?v=tIBN9VJ0S4a    The conclusion is that you definitely can combine scrum and Design thinking.    Approach:    In terms of approach, I wouldn't be much different from what I did in this project. I only see advantages of combining scrum  with mind mapping. As described in the alinia insight, there are only benefits.\n",
      "\n",
      "\n",
      "Centers\n",
      "Waseem Mabunda  591 Smith Centers Apt. 656\n",
      "Joshuamouth, RI 95963 ( The Netherlands)  410.526.1667  vpi@mn.nl\n",
      "\n",
      "Mind Mapping,      Challenge:     For several years I have been working for an Asset manager in the Netherlands. During this period I have been involved in many  projects. Certainly in the world of asset management, much has changed in recent years in the area of Law and Regulations.  What I mainly experience in these projects is that all departments have a different interest in starting a new project. This  certainly does not benefit the project. How do you get everyone to complete a project in the common interest and how do you  motivate everyone who participate in the project?    Selection:    An improvement project can be approached in different ways. The most common way is the scrum approach. We work in  multidisciplinary teams that work in short sprints, with a fixed length of 1 to 4 weeks. Cooperation is very important and  everyone must be able to respond quickly to changing circumstances. Scrum is based on the theory of empirical process  control, or empiricism. Empiricism assumes that knowledge arises from experience and making decisions based on what is  known.     I chose mind mapping because I am looking for a way to show the creativity colleagues always have at the start of a project,  to  keep this up to date and very important to keep it visible.   But also with the thoughts to keep colleagues motivated and to show how their creativity contributes to the project.    So I want to see if scrum can be combined with Design Thinking and especially with Mind mapping.    Application:    When starting a new project at work, I checked whether it is workable to combine the scrum approach with Mind Mapping. The  central theme was to increase the STP (Straight through processing) rate for a specific product that we trade with an x  percentage.    As a scrum team, we have tried to provide insight into the various topics related to the 'increase STP rate' via a paper diagram.  Each team member could indicate in this diagram his or her creativity which related to increasing the STP rate.    After this we went to see if there was a connection between certain ideas. We quickly learned that certain ideas could be  combined and that certain steps in the project could be skipped. By combining scrum work and mind mapping, we were able to  go live with implementation faster and increase STP speed step by step.    By making the project visible through a diagram, colleagues also indicated that this gave them more energy to participate in the  project.\n",
      "\n",
      "D e s i g n  T h i n k i n g\n",
      "\n",
      "Insight:    The insight I got to combine scrum with mind mapping (Design thinking) is that if you make everyone's creativity and thinking  visible through Mind mapping, you will come sooner to a solid solution to complete a project. The feedback we received is that  it also gives more energy to colleagues who have participated in this project.     The biggest challenge was to create support for this new way of working.     At the beginning of the project, we showed a short video of how mind mapping works. This gave us immediate support from  our fellow team members to combine scrum with mind mapping.      https://www.youtube.com/watch?v=tIBN9VJ0S4a    The conclusion is that you definitely can combine scrum and Design thinking.    Approach:    In terms of approach, I wouldn't be much different from what I did in this project. I only see advantages of combining scrum  with mind mapping. As described in the alinia insight, there are only benefits.\n",
      "\n",
      "\n",
      "Apt\n",
      "Waseem Mabunda  591 Smith Centers Apt. 656\n",
      "Joshuamouth, RI 95963 ( The Netherlands)  410.526.1667  vpi@mn.nl\n",
      "\n",
      "Mind Mapping,      Challenge:     For several years I have been working for an Asset manager in the Netherlands. During this period I have been involved in many  projects. Certainly in the world of asset management, much has changed in recent years in the area of Law and Regulations.  What I mainly experience in these projects is that all departments have a different interest in starting a new project. This  certainly does not benefit the project. How do you get everyone to complete a project in the common interest and how do you  motivate everyone who participate in the project?    Selection:    An improvement project can be approached in different ways. The most common way is the scrum approach. We work in  multidisciplinary teams that work in short sprints, with a fixed length of 1 to 4 weeks. Cooperation is very important and  everyone must be able to respond quickly to changing circumstances. Scrum is based on the theory of empirical process  control, or empiricism. Empiricism assumes that knowledge arises from experience and making decisions based on what is  known.     I chose mind mapping because I am looking for a way to show the creativity colleagues always have at the start of a project,  to  keep this up to date and very important to keep it visible.   But also with the thoughts to keep colleagues motivated and to show how their creativity contributes to the project.    So I want to see if scrum can be combined with Design Thinking and especially with Mind mapping.    Application:    When starting a new project at work, I checked whether it is workable to combine the scrum approach with Mind Mapping. The  central theme was to increase the STP (Straight through processing) rate for a specific product that we trade with an x  percentage.    As a scrum team, we have tried to provide insight into the various topics related to the 'increase STP rate' via a paper diagram.  Each team member could indicate in this diagram his or her creativity which related to increasing the STP rate.    After this we went to see if there was a connection between certain ideas. We quickly learned that certain ideas could be  combined and that certain steps in the project could be skipped. By combining scrum work and mind mapping, we were able to  go live with implementation faster and increase STP speed step by step.    By making the project visible through a diagram, colleagues also indicated that this gave them more energy to participate in the  project.\n",
      "\n",
      "D e s i g n  T h i n k i n g\n",
      "\n",
      "Insight:    The insight I got to combine scrum with mind mapping (Design thinking) is that if you make everyone's creativity and thinking  visible through Mind mapping, you will come sooner to a solid solution to complete a project. The feedback we received is that  it also gives more energy to colleagues who have participated in this project.     The biggest challenge was to create support for this new way of working.     At the beginning of the project, we showed a short video of how mind mapping works. This gave us immediate support from  our fellow team members to combine scrum with mind mapping.      https://www.youtube.com/watch?v=tIBN9VJ0S4a    The conclusion is that you definitely can combine scrum and Design thinking.    Approach:    In terms of approach, I wouldn't be much different from what I did in this project. I only see advantages of combining scrum  with mind mapping. As described in the alinia insight, there are only benefits.\n",
      "\n",
      "\n",
      ".\n",
      "Waseem Mabunda  591 Smith Centers Apt. 656\n",
      "Joshuamouth, RI 95963 ( The Netherlands)  410.526.1667  vpi@mn.nl\n",
      "\n",
      "Mind Mapping,      Challenge:     For several years I have been working for an Asset manager in the Netherlands. During this period I have been involved in many  projects. Certainly in the world of asset management, much has changed in recent years in the area of Law and Regulations.  What I mainly experience in these projects is that all departments have a different interest in starting a new project. This  certainly does not benefit the project. How do you get everyone to complete a project in the common interest and how do you  motivate everyone who participate in the project?    Selection:    An improvement project can be approached in different ways. The most common way is the scrum approach. We work in  multidisciplinary teams that work in short sprints, with a fixed length of 1 to 4 weeks. Cooperation is very important and  everyone must be able to respond quickly to changing circumstances. Scrum is based on the theory of empirical process  control, or empiricism. Empiricism assumes that knowledge arises from experience and making decisions based on what is  known.     I chose mind mapping because I am looking for a way to show the creativity colleagues always have at the start of a project,  to  keep this up to date and very important to keep it visible.   But also with the thoughts to keep colleagues motivated and to show how their creativity contributes to the project.    So I want to see if scrum can be combined with Design Thinking and especially with Mind mapping.    Application:    When starting a new project at work, I checked whether it is workable to combine the scrum approach with Mind Mapping. The  central theme was to increase the STP (Straight through processing) rate for a specific product that we trade with an x  percentage.    As a scrum team, we have tried to provide insight into the various topics related to the 'increase STP rate' via a paper diagram.  Each team member could indicate in this diagram his or her creativity which related to increasing the STP rate.    After this we went to see if there was a connection between certain ideas. We quickly learned that certain ideas could be  combined and that certain steps in the project could be skipped. By combining scrum work and mind mapping, we were able to  go live with implementation faster and increase STP speed step by step.    By making the project visible through a diagram, colleagues also indicated that this gave them more energy to participate in the  project.\n",
      "\n",
      "D e s i g n  T h i n k i n g\n",
      "\n",
      "Insight:    The insight I got to combine scrum with mind mapping (Design thinking) is that if you make everyone's creativity and thinking  visible through Mind mapping, you will come sooner to a solid solution to complete a project. The feedback we received is that  it also gives more energy to colleagues who have participated in this project.     The biggest challenge was to create support for this new way of working.     At the beginning of the project, we showed a short video of how mind mapping works. This gave us immediate support from  our fellow team members to combine scrum with mind mapping.      https://www.youtube.com/watch?v=tIBN9VJ0S4a    The conclusion is that you definitely can combine scrum and Design thinking.    Approach:    In terms of approach, I wouldn't be much different from what I did in this project. I only see advantages of combining scrum  with mind mapping. As described in the alinia insight, there are only benefits.\n",
      "\n",
      "\n",
      "656\n",
      "Waseem Mabunda  591 Smith Centers Apt. 656\n",
      "Joshuamouth, RI 95963 ( The Netherlands)  410.526.1667  vpi@mn.nl\n",
      "\n",
      "Mind Mapping,      Challenge:     For several years I have been working for an Asset manager in the Netherlands. During this period I have been involved in many  projects. Certainly in the world of asset management, much has changed in recent years in the area of Law and Regulations.  What I mainly experience in these projects is that all departments have a different interest in starting a new project. This  certainly does not benefit the project. How do you get everyone to complete a project in the common interest and how do you  motivate everyone who participate in the project?    Selection:    An improvement project can be approached in different ways. The most common way is the scrum approach. We work in  multidisciplinary teams that work in short sprints, with a fixed length of 1 to 4 weeks. Cooperation is very important and  everyone must be able to respond quickly to changing circumstances. Scrum is based on the theory of empirical process  control, or empiricism. Empiricism assumes that knowledge arises from experience and making decisions based on what is  known.     I chose mind mapping because I am looking for a way to show the creativity colleagues always have at the start of a project,  to  keep this up to date and very important to keep it visible.   But also with the thoughts to keep colleagues motivated and to show how their creativity contributes to the project.    So I want to see if scrum can be combined with Design Thinking and especially with Mind mapping.    Application:    When starting a new project at work, I checked whether it is workable to combine the scrum approach with Mind Mapping. The  central theme was to increase the STP (Straight through processing) rate for a specific product that we trade with an x  percentage.    As a scrum team, we have tried to provide insight into the various topics related to the 'increase STP rate' via a paper diagram.  Each team member could indicate in this diagram his or her creativity which related to increasing the STP rate.    After this we went to see if there was a connection between certain ideas. We quickly learned that certain ideas could be  combined and that certain steps in the project could be skipped. By combining scrum work and mind mapping, we were able to  go live with implementation faster and increase STP speed step by step.    By making the project visible through a diagram, colleagues also indicated that this gave them more energy to participate in the  project.\n",
      "\n",
      "D e s i g n  T h i n k i n g\n",
      "\n",
      "Insight:    The insight I got to combine scrum with mind mapping (Design thinking) is that if you make everyone's creativity and thinking  visible through Mind mapping, you will come sooner to a solid solution to complete a project. The feedback we received is that  it also gives more energy to colleagues who have participated in this project.     The biggest challenge was to create support for this new way of working.     At the beginning of the project, we showed a short video of how mind mapping works. This gave us immediate support from  our fellow team members to combine scrum with mind mapping.      https://www.youtube.com/watch?v=tIBN9VJ0S4a    The conclusion is that you definitely can combine scrum and Design thinking.    Approach:    In terms of approach, I wouldn't be much different from what I did in this project. I only see advantages of combining scrum  with mind mapping. As described in the alinia insight, there are only benefits.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Waseem Mabunda  591 Smith Centers Apt. 656\n",
      "Joshuamouth, RI 95963 ( The Netherlands)  410.526.1667  vpi@mn.nl\n",
      "\n",
      "Mind Mapping,      Challenge:     For several years I have been working for an Asset manager in the Netherlands. During this period I have been involved in many  projects. Certainly in the world of asset management, much has changed in recent years in the area of Law and Regulations.  What I mainly experience in these projects is that all departments have a different interest in starting a new project. This  certainly does not benefit the project. How do you get everyone to complete a project in the common interest and how do you  motivate everyone who participate in the project?    Selection:    An improvement project can be approached in different ways. The most common way is the scrum approach. We work in  multidisciplinary teams that work in short sprints, with a fixed length of 1 to 4 weeks. Cooperation is very important and  everyone must be able to respond quickly to changing circumstances. Scrum is based on the theory of empirical process  control, or empiricism. Empiricism assumes that knowledge arises from experience and making decisions based on what is  known.     I chose mind mapping because I am looking for a way to show the creativity colleagues always have at the start of a project,  to  keep this up to date and very important to keep it visible.   But also with the thoughts to keep colleagues motivated and to show how their creativity contributes to the project.    So I want to see if scrum can be combined with Design Thinking and especially with Mind mapping.    Application:    When starting a new project at work, I checked whether it is workable to combine the scrum approach with Mind Mapping. The  central theme was to increase the STP (Straight through processing) rate for a specific product that we trade with an x  percentage.    As a scrum team, we have tried to provide insight into the various topics related to the 'increase STP rate' via a paper diagram.  Each team member could indicate in this diagram his or her creativity which related to increasing the STP rate.    After this we went to see if there was a connection between certain ideas. We quickly learned that certain ideas could be  combined and that certain steps in the project could be skipped. By combining scrum work and mind mapping, we were able to  go live with implementation faster and increase STP speed step by step.    By making the project visible through a diagram, colleagues also indicated that this gave them more energy to participate in the  project.\n",
      "\n",
      "D e s i g n  T h i n k i n g\n",
      "\n",
      "Insight:    The insight I got to combine scrum with mind mapping (Design thinking) is that if you make everyone's creativity and thinking  visible through Mind mapping, you will come sooner to a solid solution to complete a project. The feedback we received is that  it also gives more energy to colleagues who have participated in this project.     The biggest challenge was to create support for this new way of working.     At the beginning of the project, we showed a short video of how mind mapping works. This gave us immediate support from  our fellow team members to combine scrum with mind mapping.      https://www.youtube.com/watch?v=tIBN9VJ0S4a    The conclusion is that you definitely can combine scrum and Design thinking.    Approach:    In terms of approach, I wouldn't be much different from what I did in this project. I only see advantages of combining scrum  with mind mapping. As described in the alinia insight, there are only benefits.\n",
      "\n",
      "\n",
      "Joshuamouth\n",
      "Waseem Mabunda  591 Smith Centers Apt. 656\n",
      "Joshuamouth, RI 95963 ( The Netherlands)  410.526.1667  vpi@mn.nl\n",
      "\n",
      "Mind Mapping,      Challenge:     For several years I have been working for an Asset manager in the Netherlands. During this period I have been involved in many  projects. Certainly in the world of asset management, much has changed in recent years in the area of Law and Regulations.  What I mainly experience in these projects is that all departments have a different interest in starting a new project. This  certainly does not benefit the project. How do you get everyone to complete a project in the common interest and how do you  motivate everyone who participate in the project?    Selection:    An improvement project can be approached in different ways. The most common way is the scrum approach. We work in  multidisciplinary teams that work in short sprints, with a fixed length of 1 to 4 weeks. Cooperation is very important and  everyone must be able to respond quickly to changing circumstances. Scrum is based on the theory of empirical process  control, or empiricism. Empiricism assumes that knowledge arises from experience and making decisions based on what is  known.     I chose mind mapping because I am looking for a way to show the creativity colleagues always have at the start of a project,  to  keep this up to date and very important to keep it visible.   But also with the thoughts to keep colleagues motivated and to show how their creativity contributes to the project.    So I want to see if scrum can be combined with Design Thinking and especially with Mind mapping.    Application:    When starting a new project at work, I checked whether it is workable to combine the scrum approach with Mind Mapping. The  central theme was to increase the STP (Straight through processing) rate for a specific product that we trade with an x  percentage.    As a scrum team, we have tried to provide insight into the various topics related to the 'increase STP rate' via a paper diagram.  Each team member could indicate in this diagram his or her creativity which related to increasing the STP rate.    After this we went to see if there was a connection between certain ideas. We quickly learned that certain ideas could be  combined and that certain steps in the project could be skipped. By combining scrum work and mind mapping, we were able to  go live with implementation faster and increase STP speed step by step.    By making the project visible through a diagram, colleagues also indicated that this gave them more energy to participate in the  project.\n",
      "\n",
      "D e s i g n  T h i n k i n g\n",
      "\n",
      "Insight:    The insight I got to combine scrum with mind mapping (Design thinking) is that if you make everyone's creativity and thinking  visible through Mind mapping, you will come sooner to a solid solution to complete a project. The feedback we received is that  it also gives more energy to colleagues who have participated in this project.     The biggest challenge was to create support for this new way of working.     At the beginning of the project, we showed a short video of how mind mapping works. This gave us immediate support from  our fellow team members to combine scrum with mind mapping.      https://www.youtube.com/watch?v=tIBN9VJ0S4a    The conclusion is that you definitely can combine scrum and Design thinking.    Approach:    In terms of approach, I wouldn't be much different from what I did in this project. I only see advantages of combining scrum  with mind mapping. As described in the alinia insight, there are only benefits.\n",
      "\n",
      "\n",
      ",\n",
      "Waseem Mabunda  591 Smith Centers Apt. 656\n",
      "Joshuamouth, RI 95963 ( The Netherlands)  410.526.1667  vpi@mn.nl\n",
      "\n",
      "Mind Mapping,      Challenge:     For several years I have been working for an Asset manager in the Netherlands. During this period I have been involved in many  projects. Certainly in the world of asset management, much has changed in recent years in the area of Law and Regulations.  What I mainly experience in these projects is that all departments have a different interest in starting a new project. This  certainly does not benefit the project. How do you get everyone to complete a project in the common interest and how do you  motivate everyone who participate in the project?    Selection:    An improvement project can be approached in different ways. The most common way is the scrum approach. We work in  multidisciplinary teams that work in short sprints, with a fixed length of 1 to 4 weeks. Cooperation is very important and  everyone must be able to respond quickly to changing circumstances. Scrum is based on the theory of empirical process  control, or empiricism. Empiricism assumes that knowledge arises from experience and making decisions based on what is  known.     I chose mind mapping because I am looking for a way to show the creativity colleagues always have at the start of a project,  to  keep this up to date and very important to keep it visible.   But also with the thoughts to keep colleagues motivated and to show how their creativity contributes to the project.    So I want to see if scrum can be combined with Design Thinking and especially with Mind mapping.    Application:    When starting a new project at work, I checked whether it is workable to combine the scrum approach with Mind Mapping. The  central theme was to increase the STP (Straight through processing) rate for a specific product that we trade with an x  percentage.    As a scrum team, we have tried to provide insight into the various topics related to the 'increase STP rate' via a paper diagram.  Each team member could indicate in this diagram his or her creativity which related to increasing the STP rate.    After this we went to see if there was a connection between certain ideas. We quickly learned that certain ideas could be  combined and that certain steps in the project could be skipped. By combining scrum work and mind mapping, we were able to  go live with implementation faster and increase STP speed step by step.    By making the project visible through a diagram, colleagues also indicated that this gave them more energy to participate in the  project.\n",
      "\n",
      "D e s i g n  T h i n k i n g\n",
      "\n",
      "Insight:    The insight I got to combine scrum with mind mapping (Design thinking) is that if you make everyone's creativity and thinking  visible through Mind mapping, you will come sooner to a solid solution to complete a project. The feedback we received is that  it also gives more energy to colleagues who have participated in this project.     The biggest challenge was to create support for this new way of working.     At the beginning of the project, we showed a short video of how mind mapping works. This gave us immediate support from  our fellow team members to combine scrum with mind mapping.      https://www.youtube.com/watch?v=tIBN9VJ0S4a    The conclusion is that you definitely can combine scrum and Design thinking.    Approach:    In terms of approach, I wouldn't be much different from what I did in this project. I only see advantages of combining scrum  with mind mapping. As described in the alinia insight, there are only benefits.\n",
      "\n",
      "\n",
      "RI\n",
      "Waseem Mabunda  591 Smith Centers Apt. 656\n",
      "Joshuamouth, RI 95963 ( The Netherlands)  410.526.1667  vpi@mn.nl\n",
      "\n",
      "Mind Mapping,      Challenge:     For several years I have been working for an Asset manager in the Netherlands. During this period I have been involved in many  projects. Certainly in the world of asset management, much has changed in recent years in the area of Law and Regulations.  What I mainly experience in these projects is that all departments have a different interest in starting a new project. This  certainly does not benefit the project. How do you get everyone to complete a project in the common interest and how do you  motivate everyone who participate in the project?    Selection:    An improvement project can be approached in different ways. The most common way is the scrum approach. We work in  multidisciplinary teams that work in short sprints, with a fixed length of 1 to 4 weeks. Cooperation is very important and  everyone must be able to respond quickly to changing circumstances. Scrum is based on the theory of empirical process  control, or empiricism. Empiricism assumes that knowledge arises from experience and making decisions based on what is  known.     I chose mind mapping because I am looking for a way to show the creativity colleagues always have at the start of a project,  to  keep this up to date and very important to keep it visible.   But also with the thoughts to keep colleagues motivated and to show how their creativity contributes to the project.    So I want to see if scrum can be combined with Design Thinking and especially with Mind mapping.    Application:    When starting a new project at work, I checked whether it is workable to combine the scrum approach with Mind Mapping. The  central theme was to increase the STP (Straight through processing) rate for a specific product that we trade with an x  percentage.    As a scrum team, we have tried to provide insight into the various topics related to the 'increase STP rate' via a paper diagram.  Each team member could indicate in this diagram his or her creativity which related to increasing the STP rate.    After this we went to see if there was a connection between certain ideas. We quickly learned that certain ideas could be  combined and that certain steps in the project could be skipped. By combining scrum work and mind mapping, we were able to  go live with implementation faster and increase STP speed step by step.    By making the project visible through a diagram, colleagues also indicated that this gave them more energy to participate in the  project.\n",
      "\n",
      "D e s i g n  T h i n k i n g\n",
      "\n",
      "Insight:    The insight I got to combine scrum with mind mapping (Design thinking) is that if you make everyone's creativity and thinking  visible through Mind mapping, you will come sooner to a solid solution to complete a project. The feedback we received is that  it also gives more energy to colleagues who have participated in this project.     The biggest challenge was to create support for this new way of working.     At the beginning of the project, we showed a short video of how mind mapping works. This gave us immediate support from  our fellow team members to combine scrum with mind mapping.      https://www.youtube.com/watch?v=tIBN9VJ0S4a    The conclusion is that you definitely can combine scrum and Design thinking.    Approach:    In terms of approach, I wouldn't be much different from what I did in this project. I only see advantages of combining scrum  with mind mapping. As described in the alinia insight, there are only benefits.\n",
      "\n",
      "\n",
      "95963\n",
      "Reflection – Learning Launch of 1861. Milano\n",
      "\n",
      "Challenge & Selection\n",
      "\n",
      "During my second-to-last year of high-school (2013), I decided to team up with two friends of  mine and explore a market which at the time was still uncharted: create a fashion brand  aimed towards the street culture and based on Milan, our hometown. If the former - the  street-culture-oriented fashion - was an upcoming trend back then which was just starting to  take off, the latter was yet to be covered and provided an interesting ground to experiment  some entrepreneurship ideas off some friends’ impressions and insights.  We thus set up all of the necessary contacts, the business model, and got ourselves an  identity (1861. Milano - 743 Erika Bypass Apt. 419\n",
      "Andreahaven, IL 54207) looking forward to our first  launch, which would simply be composed of a t-shirt and a hoodie. However, even though  we already decided on the main aspects of the product line, being at our first experience in  the field we deemed useful resorting to gather some of our potential clients’ feedback  (mostly teenagers, just like us). For this, we made use of some contacts of ours to talk to  one of the main party organizations in Milan, and found out about a date of a party which  would suit perfectly our time-constraint needs with respect to the products’ actual launch.  The organization of the party, who appeared interested in the project, granted us the  possibility of organizing stands at the event to promote an actual pre-launch event, in which  we could show and discuss samples directly with our potential clientbase: a technique which  just later - when attending this course - I realized being called “learning launch”.\n",
      "\n",
      "Application\n",
      "\n",
      "We then began to think how to organize the learning launch event, in order to understand  what we would need to bring on the day of the party and how to present it to the people to  get the most useful information out of it. We were aware that the participants would know in  advance of the pre-launch event - the organizers, in fact, made sure to advertise it  accordingly in the invites -, so we knew that it was an opportunity which we needed to  capitalize.  For such, we opted to focus on the fit and comfort of our first products, since we had not had  yet the possibility to receive feedback on it (whilst with the designs and prints, on the other  hand, we had already managed to gather useful information via surveys and brief  interviews). We brought to the party 1861-themed roll-ups and posters to create cozy and  recognizable stands, in which we had potential customers try different kinds of fits and  garment models of the products - the t-shirt and the hoodie - that we had decided to launch.  We had skinnier/more loose fits, a couple of different material combinations and big smiles  on our faces, so the party finally began as we waited impatiently the first people to come by  (we decided not to go and chase them out in the wild, as it was not the most effective  approach to adopt in that environment).\n",
      "\n",
      "Insight & Approach\n",
      "\n",
      "The learning launch event was a success, and really helped us also in gaining valuable  traction among friends of the potential clients by word-of-mouth, a nice side-effect to add  along! Naturally, though, our main goal was a different one as previously specified, which we\n",
      "\n",
      "managed to cover with a concrete deal of useful gathered information. For instance, we  realized that a skinnier fit for the t-shirts was welcomed, and that the 100% cotton samples  that we brought with us were preferred; for what concerns the hoodies, we realized that  some samples had too-small hoods (thus a larger, less tight on the scalp one was preferred),  fits which were looser on the trunk and tighter on the arms were more liked and finally a  mixture which was - unlike the t-shirts - not 100% cotton, rather 80% cotton and 20%  polyester gave the best combination of on-skin comfort and wearability feel. At the end of the  night we had some people approaching us to buy some of the samples, too! One extra perk  that made us even more enthusiast of the experience.\n",
      "\n",
      "After that, we proceeded with our launch campaign and sold the two models which we got  feedback on at the event. We had planned a second, four-garment launch for later that year  and were looking forward to choosing amongst the designs that we were coming up with,  when eventually other commitments entered each one of our lives and we could not properly  follow up the brand.  However, the experience enriched us on the ways in which such a tool could become useful  when approaching a problem to solve (in our case, the best possible products that we could  enter the market with), and the reality is that - albeit on different scales -, it could really be  useful in a very wide variety of scenarios! If we were, though, to proceed with the second  launch as we had planned, we would have used the same learning-launch approach for what  concerns the garments to use for our products. However, we may have wanted to extend it  to different designs on which giving our potential customers the possibility to choose from,  although the visualization approach (that we resorted to for the same task during our first  launch) revealed to be effective: having visualizations of what our products would look like  via mock-ups allows to reach a wider crowd with a less demanding organization, and to  gather important feedback on the designs based on a reliable representation of what the  finished product would look like. It is also easy to change the mock-ups on the go during  interviews in accordance to suggestions and proposals of the interviewees, so that an agile  and interactive learning process with potential customers can be instituted.\n",
      "\n",
      "\n",
      "Erika\n",
      "Reflection – Learning Launch of 1861. Milano\n",
      "\n",
      "Challenge & Selection\n",
      "\n",
      "During my second-to-last year of high-school (2013), I decided to team up with two friends of  mine and explore a market which at the time was still uncharted: create a fashion brand  aimed towards the street culture and based on Milan, our hometown. If the former - the  street-culture-oriented fashion - was an upcoming trend back then which was just starting to  take off, the latter was yet to be covered and provided an interesting ground to experiment  some entrepreneurship ideas off some friends’ impressions and insights.  We thus set up all of the necessary contacts, the business model, and got ourselves an  identity (1861. Milano - 743 Erika Bypass Apt. 419\n",
      "Andreahaven, IL 54207) looking forward to our first  launch, which would simply be composed of a t-shirt and a hoodie. However, even though  we already decided on the main aspects of the product line, being at our first experience in  the field we deemed useful resorting to gather some of our potential clients’ feedback  (mostly teenagers, just like us). For this, we made use of some contacts of ours to talk to  one of the main party organizations in Milan, and found out about a date of a party which  would suit perfectly our time-constraint needs with respect to the products’ actual launch.  The organization of the party, who appeared interested in the project, granted us the  possibility of organizing stands at the event to promote an actual pre-launch event, in which  we could show and discuss samples directly with our potential clientbase: a technique which  just later - when attending this course - I realized being called “learning launch”.\n",
      "\n",
      "Application\n",
      "\n",
      "We then began to think how to organize the learning launch event, in order to understand  what we would need to bring on the day of the party and how to present it to the people to  get the most useful information out of it. We were aware that the participants would know in  advance of the pre-launch event - the organizers, in fact, made sure to advertise it  accordingly in the invites -, so we knew that it was an opportunity which we needed to  capitalize.  For such, we opted to focus on the fit and comfort of our first products, since we had not had  yet the possibility to receive feedback on it (whilst with the designs and prints, on the other  hand, we had already managed to gather useful information via surveys and brief  interviews). We brought to the party 1861-themed roll-ups and posters to create cozy and  recognizable stands, in which we had potential customers try different kinds of fits and  garment models of the products - the t-shirt and the hoodie - that we had decided to launch.  We had skinnier/more loose fits, a couple of different material combinations and big smiles  on our faces, so the party finally began as we waited impatiently the first people to come by  (we decided not to go and chase them out in the wild, as it was not the most effective  approach to adopt in that environment).\n",
      "\n",
      "Insight & Approach\n",
      "\n",
      "The learning launch event was a success, and really helped us also in gaining valuable  traction among friends of the potential clients by word-of-mouth, a nice side-effect to add  along! Naturally, though, our main goal was a different one as previously specified, which we\n",
      "\n",
      "managed to cover with a concrete deal of useful gathered information. For instance, we  realized that a skinnier fit for the t-shirts was welcomed, and that the 100% cotton samples  that we brought with us were preferred; for what concerns the hoodies, we realized that  some samples had too-small hoods (thus a larger, less tight on the scalp one was preferred),  fits which were looser on the trunk and tighter on the arms were more liked and finally a  mixture which was - unlike the t-shirts - not 100% cotton, rather 80% cotton and 20%  polyester gave the best combination of on-skin comfort and wearability feel. At the end of the  night we had some people approaching us to buy some of the samples, too! One extra perk  that made us even more enthusiast of the experience.\n",
      "\n",
      "After that, we proceeded with our launch campaign and sold the two models which we got  feedback on at the event. We had planned a second, four-garment launch for later that year  and were looking forward to choosing amongst the designs that we were coming up with,  when eventually other commitments entered each one of our lives and we could not properly  follow up the brand.  However, the experience enriched us on the ways in which such a tool could become useful  when approaching a problem to solve (in our case, the best possible products that we could  enter the market with), and the reality is that - albeit on different scales -, it could really be  useful in a very wide variety of scenarios! If we were, though, to proceed with the second  launch as we had planned, we would have used the same learning-launch approach for what  concerns the garments to use for our products. However, we may have wanted to extend it  to different designs on which giving our potential customers the possibility to choose from,  although the visualization approach (that we resorted to for the same task during our first  launch) revealed to be effective: having visualizations of what our products would look like  via mock-ups allows to reach a wider crowd with a less demanding organization, and to  gather important feedback on the designs based on a reliable representation of what the  finished product would look like. It is also easy to change the mock-ups on the go during  interviews in accordance to suggestions and proposals of the interviewees, so that an agile  and interactive learning process with potential customers can be instituted.\n",
      "\n",
      "\n",
      "Bypass\n",
      "Reflection – Learning Launch of 1861. Milano\n",
      "\n",
      "Challenge & Selection\n",
      "\n",
      "During my second-to-last year of high-school (2013), I decided to team up with two friends of  mine and explore a market which at the time was still uncharted: create a fashion brand  aimed towards the street culture and based on Milan, our hometown. If the former - the  street-culture-oriented fashion - was an upcoming trend back then which was just starting to  take off, the latter was yet to be covered and provided an interesting ground to experiment  some entrepreneurship ideas off some friends’ impressions and insights.  We thus set up all of the necessary contacts, the business model, and got ourselves an  identity (1861. Milano - 743 Erika Bypass Apt. 419\n",
      "Andreahaven, IL 54207) looking forward to our first  launch, which would simply be composed of a t-shirt and a hoodie. However, even though  we already decided on the main aspects of the product line, being at our first experience in  the field we deemed useful resorting to gather some of our potential clients’ feedback  (mostly teenagers, just like us). For this, we made use of some contacts of ours to talk to  one of the main party organizations in Milan, and found out about a date of a party which  would suit perfectly our time-constraint needs with respect to the products’ actual launch.  The organization of the party, who appeared interested in the project, granted us the  possibility of organizing stands at the event to promote an actual pre-launch event, in which  we could show and discuss samples directly with our potential clientbase: a technique which  just later - when attending this course - I realized being called “learning launch”.\n",
      "\n",
      "Application\n",
      "\n",
      "We then began to think how to organize the learning launch event, in order to understand  what we would need to bring on the day of the party and how to present it to the people to  get the most useful information out of it. We were aware that the participants would know in  advance of the pre-launch event - the organizers, in fact, made sure to advertise it  accordingly in the invites -, so we knew that it was an opportunity which we needed to  capitalize.  For such, we opted to focus on the fit and comfort of our first products, since we had not had  yet the possibility to receive feedback on it (whilst with the designs and prints, on the other  hand, we had already managed to gather useful information via surveys and brief  interviews). We brought to the party 1861-themed roll-ups and posters to create cozy and  recognizable stands, in which we had potential customers try different kinds of fits and  garment models of the products - the t-shirt and the hoodie - that we had decided to launch.  We had skinnier/more loose fits, a couple of different material combinations and big smiles  on our faces, so the party finally began as we waited impatiently the first people to come by  (we decided not to go and chase them out in the wild, as it was not the most effective  approach to adopt in that environment).\n",
      "\n",
      "Insight & Approach\n",
      "\n",
      "The learning launch event was a success, and really helped us also in gaining valuable  traction among friends of the potential clients by word-of-mouth, a nice side-effect to add  along! Naturally, though, our main goal was a different one as previously specified, which we\n",
      "\n",
      "managed to cover with a concrete deal of useful gathered information. For instance, we  realized that a skinnier fit for the t-shirts was welcomed, and that the 100% cotton samples  that we brought with us were preferred; for what concerns the hoodies, we realized that  some samples had too-small hoods (thus a larger, less tight on the scalp one was preferred),  fits which were looser on the trunk and tighter on the arms were more liked and finally a  mixture which was - unlike the t-shirts - not 100% cotton, rather 80% cotton and 20%  polyester gave the best combination of on-skin comfort and wearability feel. At the end of the  night we had some people approaching us to buy some of the samples, too! One extra perk  that made us even more enthusiast of the experience.\n",
      "\n",
      "After that, we proceeded with our launch campaign and sold the two models which we got  feedback on at the event. We had planned a second, four-garment launch for later that year  and were looking forward to choosing amongst the designs that we were coming up with,  when eventually other commitments entered each one of our lives and we could not properly  follow up the brand.  However, the experience enriched us on the ways in which such a tool could become useful  when approaching a problem to solve (in our case, the best possible products that we could  enter the market with), and the reality is that - albeit on different scales -, it could really be  useful in a very wide variety of scenarios! If we were, though, to proceed with the second  launch as we had planned, we would have used the same learning-launch approach for what  concerns the garments to use for our products. However, we may have wanted to extend it  to different designs on which giving our potential customers the possibility to choose from,  although the visualization approach (that we resorted to for the same task during our first  launch) revealed to be effective: having visualizations of what our products would look like  via mock-ups allows to reach a wider crowd with a less demanding organization, and to  gather important feedback on the designs based on a reliable representation of what the  finished product would look like. It is also easy to change the mock-ups on the go during  interviews in accordance to suggestions and proposals of the interviewees, so that an agile  and interactive learning process with potential customers can be instituted.\n",
      "\n",
      "\n",
      "Apt\n",
      "Reflection – Learning Launch of 1861. Milano\n",
      "\n",
      "Challenge & Selection\n",
      "\n",
      "During my second-to-last year of high-school (2013), I decided to team up with two friends of  mine and explore a market which at the time was still uncharted: create a fashion brand  aimed towards the street culture and based on Milan, our hometown. If the former - the  street-culture-oriented fashion - was an upcoming trend back then which was just starting to  take off, the latter was yet to be covered and provided an interesting ground to experiment  some entrepreneurship ideas off some friends’ impressions and insights.  We thus set up all of the necessary contacts, the business model, and got ourselves an  identity (1861. Milano - 743 Erika Bypass Apt. 419\n",
      "Andreahaven, IL 54207) looking forward to our first  launch, which would simply be composed of a t-shirt and a hoodie. However, even though  we already decided on the main aspects of the product line, being at our first experience in  the field we deemed useful resorting to gather some of our potential clients’ feedback  (mostly teenagers, just like us). For this, we made use of some contacts of ours to talk to  one of the main party organizations in Milan, and found out about a date of a party which  would suit perfectly our time-constraint needs with respect to the products’ actual launch.  The organization of the party, who appeared interested in the project, granted us the  possibility of organizing stands at the event to promote an actual pre-launch event, in which  we could show and discuss samples directly with our potential clientbase: a technique which  just later - when attending this course - I realized being called “learning launch”.\n",
      "\n",
      "Application\n",
      "\n",
      "We then began to think how to organize the learning launch event, in order to understand  what we would need to bring on the day of the party and how to present it to the people to  get the most useful information out of it. We were aware that the participants would know in  advance of the pre-launch event - the organizers, in fact, made sure to advertise it  accordingly in the invites -, so we knew that it was an opportunity which we needed to  capitalize.  For such, we opted to focus on the fit and comfort of our first products, since we had not had  yet the possibility to receive feedback on it (whilst with the designs and prints, on the other  hand, we had already managed to gather useful information via surveys and brief  interviews). We brought to the party 1861-themed roll-ups and posters to create cozy and  recognizable stands, in which we had potential customers try different kinds of fits and  garment models of the products - the t-shirt and the hoodie - that we had decided to launch.  We had skinnier/more loose fits, a couple of different material combinations and big smiles  on our faces, so the party finally began as we waited impatiently the first people to come by  (we decided not to go and chase them out in the wild, as it was not the most effective  approach to adopt in that environment).\n",
      "\n",
      "Insight & Approach\n",
      "\n",
      "The learning launch event was a success, and really helped us also in gaining valuable  traction among friends of the potential clients by word-of-mouth, a nice side-effect to add  along! Naturally, though, our main goal was a different one as previously specified, which we\n",
      "\n",
      "managed to cover with a concrete deal of useful gathered information. For instance, we  realized that a skinnier fit for the t-shirts was welcomed, and that the 100% cotton samples  that we brought with us were preferred; for what concerns the hoodies, we realized that  some samples had too-small hoods (thus a larger, less tight on the scalp one was preferred),  fits which were looser on the trunk and tighter on the arms were more liked and finally a  mixture which was - unlike the t-shirts - not 100% cotton, rather 80% cotton and 20%  polyester gave the best combination of on-skin comfort and wearability feel. At the end of the  night we had some people approaching us to buy some of the samples, too! One extra perk  that made us even more enthusiast of the experience.\n",
      "\n",
      "After that, we proceeded with our launch campaign and sold the two models which we got  feedback on at the event. We had planned a second, four-garment launch for later that year  and were looking forward to choosing amongst the designs that we were coming up with,  when eventually other commitments entered each one of our lives and we could not properly  follow up the brand.  However, the experience enriched us on the ways in which such a tool could become useful  when approaching a problem to solve (in our case, the best possible products that we could  enter the market with), and the reality is that - albeit on different scales -, it could really be  useful in a very wide variety of scenarios! If we were, though, to proceed with the second  launch as we had planned, we would have used the same learning-launch approach for what  concerns the garments to use for our products. However, we may have wanted to extend it  to different designs on which giving our potential customers the possibility to choose from,  although the visualization approach (that we resorted to for the same task during our first  launch) revealed to be effective: having visualizations of what our products would look like  via mock-ups allows to reach a wider crowd with a less demanding organization, and to  gather important feedback on the designs based on a reliable representation of what the  finished product would look like. It is also easy to change the mock-ups on the go during  interviews in accordance to suggestions and proposals of the interviewees, so that an agile  and interactive learning process with potential customers can be instituted.\n",
      "\n",
      "\n",
      ".\n",
      "Reflection – Learning Launch of 1861. Milano\n",
      "\n",
      "Challenge & Selection\n",
      "\n",
      "During my second-to-last year of high-school (2013), I decided to team up with two friends of  mine and explore a market which at the time was still uncharted: create a fashion brand  aimed towards the street culture and based on Milan, our hometown. If the former - the  street-culture-oriented fashion - was an upcoming trend back then which was just starting to  take off, the latter was yet to be covered and provided an interesting ground to experiment  some entrepreneurship ideas off some friends’ impressions and insights.  We thus set up all of the necessary contacts, the business model, and got ourselves an  identity (1861. Milano - 743 Erika Bypass Apt. 419\n",
      "Andreahaven, IL 54207) looking forward to our first  launch, which would simply be composed of a t-shirt and a hoodie. However, even though  we already decided on the main aspects of the product line, being at our first experience in  the field we deemed useful resorting to gather some of our potential clients’ feedback  (mostly teenagers, just like us). For this, we made use of some contacts of ours to talk to  one of the main party organizations in Milan, and found out about a date of a party which  would suit perfectly our time-constraint needs with respect to the products’ actual launch.  The organization of the party, who appeared interested in the project, granted us the  possibility of organizing stands at the event to promote an actual pre-launch event, in which  we could show and discuss samples directly with our potential clientbase: a technique which  just later - when attending this course - I realized being called “learning launch”.\n",
      "\n",
      "Application\n",
      "\n",
      "We then began to think how to organize the learning launch event, in order to understand  what we would need to bring on the day of the party and how to present it to the people to  get the most useful information out of it. We were aware that the participants would know in  advance of the pre-launch event - the organizers, in fact, made sure to advertise it  accordingly in the invites -, so we knew that it was an opportunity which we needed to  capitalize.  For such, we opted to focus on the fit and comfort of our first products, since we had not had  yet the possibility to receive feedback on it (whilst with the designs and prints, on the other  hand, we had already managed to gather useful information via surveys and brief  interviews). We brought to the party 1861-themed roll-ups and posters to create cozy and  recognizable stands, in which we had potential customers try different kinds of fits and  garment models of the products - the t-shirt and the hoodie - that we had decided to launch.  We had skinnier/more loose fits, a couple of different material combinations and big smiles  on our faces, so the party finally began as we waited impatiently the first people to come by  (we decided not to go and chase them out in the wild, as it was not the most effective  approach to adopt in that environment).\n",
      "\n",
      "Insight & Approach\n",
      "\n",
      "The learning launch event was a success, and really helped us also in gaining valuable  traction among friends of the potential clients by word-of-mouth, a nice side-effect to add  along! Naturally, though, our main goal was a different one as previously specified, which we\n",
      "\n",
      "managed to cover with a concrete deal of useful gathered information. For instance, we  realized that a skinnier fit for the t-shirts was welcomed, and that the 100% cotton samples  that we brought with us were preferred; for what concerns the hoodies, we realized that  some samples had too-small hoods (thus a larger, less tight on the scalp one was preferred),  fits which were looser on the trunk and tighter on the arms were more liked and finally a  mixture which was - unlike the t-shirts - not 100% cotton, rather 80% cotton and 20%  polyester gave the best combination of on-skin comfort and wearability feel. At the end of the  night we had some people approaching us to buy some of the samples, too! One extra perk  that made us even more enthusiast of the experience.\n",
      "\n",
      "After that, we proceeded with our launch campaign and sold the two models which we got  feedback on at the event. We had planned a second, four-garment launch for later that year  and were looking forward to choosing amongst the designs that we were coming up with,  when eventually other commitments entered each one of our lives and we could not properly  follow up the brand.  However, the experience enriched us on the ways in which such a tool could become useful  when approaching a problem to solve (in our case, the best possible products that we could  enter the market with), and the reality is that - albeit on different scales -, it could really be  useful in a very wide variety of scenarios! If we were, though, to proceed with the second  launch as we had planned, we would have used the same learning-launch approach for what  concerns the garments to use for our products. However, we may have wanted to extend it  to different designs on which giving our potential customers the possibility to choose from,  although the visualization approach (that we resorted to for the same task during our first  launch) revealed to be effective: having visualizations of what our products would look like  via mock-ups allows to reach a wider crowd with a less demanding organization, and to  gather important feedback on the designs based on a reliable representation of what the  finished product would look like. It is also easy to change the mock-ups on the go during  interviews in accordance to suggestions and proposals of the interviewees, so that an agile  and interactive learning process with potential customers can be instituted.\n",
      "\n",
      "\n",
      "419\n",
      "Reflection – Learning Launch of 1861. Milano\n",
      "\n",
      "Challenge & Selection\n",
      "\n",
      "During my second-to-last year of high-school (2013), I decided to team up with two friends of  mine and explore a market which at the time was still uncharted: create a fashion brand  aimed towards the street culture and based on Milan, our hometown. If the former - the  street-culture-oriented fashion - was an upcoming trend back then which was just starting to  take off, the latter was yet to be covered and provided an interesting ground to experiment  some entrepreneurship ideas off some friends’ impressions and insights.  We thus set up all of the necessary contacts, the business model, and got ourselves an  identity (1861. Milano - 743 Erika Bypass Apt. 419\n",
      "Andreahaven, IL 54207) looking forward to our first  launch, which would simply be composed of a t-shirt and a hoodie. However, even though  we already decided on the main aspects of the product line, being at our first experience in  the field we deemed useful resorting to gather some of our potential clients’ feedback  (mostly teenagers, just like us). For this, we made use of some contacts of ours to talk to  one of the main party organizations in Milan, and found out about a date of a party which  would suit perfectly our time-constraint needs with respect to the products’ actual launch.  The organization of the party, who appeared interested in the project, granted us the  possibility of organizing stands at the event to promote an actual pre-launch event, in which  we could show and discuss samples directly with our potential clientbase: a technique which  just later - when attending this course - I realized being called “learning launch”.\n",
      "\n",
      "Application\n",
      "\n",
      "We then began to think how to organize the learning launch event, in order to understand  what we would need to bring on the day of the party and how to present it to the people to  get the most useful information out of it. We were aware that the participants would know in  advance of the pre-launch event - the organizers, in fact, made sure to advertise it  accordingly in the invites -, so we knew that it was an opportunity which we needed to  capitalize.  For such, we opted to focus on the fit and comfort of our first products, since we had not had  yet the possibility to receive feedback on it (whilst with the designs and prints, on the other  hand, we had already managed to gather useful information via surveys and brief  interviews). We brought to the party 1861-themed roll-ups and posters to create cozy and  recognizable stands, in which we had potential customers try different kinds of fits and  garment models of the products - the t-shirt and the hoodie - that we had decided to launch.  We had skinnier/more loose fits, a couple of different material combinations and big smiles  on our faces, so the party finally began as we waited impatiently the first people to come by  (we decided not to go and chase them out in the wild, as it was not the most effective  approach to adopt in that environment).\n",
      "\n",
      "Insight & Approach\n",
      "\n",
      "The learning launch event was a success, and really helped us also in gaining valuable  traction among friends of the potential clients by word-of-mouth, a nice side-effect to add  along! Naturally, though, our main goal was a different one as previously specified, which we\n",
      "\n",
      "managed to cover with a concrete deal of useful gathered information. For instance, we  realized that a skinnier fit for the t-shirts was welcomed, and that the 100% cotton samples  that we brought with us were preferred; for what concerns the hoodies, we realized that  some samples had too-small hoods (thus a larger, less tight on the scalp one was preferred),  fits which were looser on the trunk and tighter on the arms were more liked and finally a  mixture which was - unlike the t-shirts - not 100% cotton, rather 80% cotton and 20%  polyester gave the best combination of on-skin comfort and wearability feel. At the end of the  night we had some people approaching us to buy some of the samples, too! One extra perk  that made us even more enthusiast of the experience.\n",
      "\n",
      "After that, we proceeded with our launch campaign and sold the two models which we got  feedback on at the event. We had planned a second, four-garment launch for later that year  and were looking forward to choosing amongst the designs that we were coming up with,  when eventually other commitments entered each one of our lives and we could not properly  follow up the brand.  However, the experience enriched us on the ways in which such a tool could become useful  when approaching a problem to solve (in our case, the best possible products that we could  enter the market with), and the reality is that - albeit on different scales -, it could really be  useful in a very wide variety of scenarios! If we were, though, to proceed with the second  launch as we had planned, we would have used the same learning-launch approach for what  concerns the garments to use for our products. However, we may have wanted to extend it  to different designs on which giving our potential customers the possibility to choose from,  although the visualization approach (that we resorted to for the same task during our first  launch) revealed to be effective: having visualizations of what our products would look like  via mock-ups allows to reach a wider crowd with a less demanding organization, and to  gather important feedback on the designs based on a reliable representation of what the  finished product would look like. It is also easy to change the mock-ups on the go during  interviews in accordance to suggestions and proposals of the interviewees, so that an agile  and interactive learning process with potential customers can be instituted.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Reflection – Learning Launch of 1861. Milano\n",
      "\n",
      "Challenge & Selection\n",
      "\n",
      "During my second-to-last year of high-school (2013), I decided to team up with two friends of  mine and explore a market which at the time was still uncharted: create a fashion brand  aimed towards the street culture and based on Milan, our hometown. If the former - the  street-culture-oriented fashion - was an upcoming trend back then which was just starting to  take off, the latter was yet to be covered and provided an interesting ground to experiment  some entrepreneurship ideas off some friends’ impressions and insights.  We thus set up all of the necessary contacts, the business model, and got ourselves an  identity (1861. Milano - 743 Erika Bypass Apt. 419\n",
      "Andreahaven, IL 54207) looking forward to our first  launch, which would simply be composed of a t-shirt and a hoodie. However, even though  we already decided on the main aspects of the product line, being at our first experience in  the field we deemed useful resorting to gather some of our potential clients’ feedback  (mostly teenagers, just like us). For this, we made use of some contacts of ours to talk to  one of the main party organizations in Milan, and found out about a date of a party which  would suit perfectly our time-constraint needs with respect to the products’ actual launch.  The organization of the party, who appeared interested in the project, granted us the  possibility of organizing stands at the event to promote an actual pre-launch event, in which  we could show and discuss samples directly with our potential clientbase: a technique which  just later - when attending this course - I realized being called “learning launch”.\n",
      "\n",
      "Application\n",
      "\n",
      "We then began to think how to organize the learning launch event, in order to understand  what we would need to bring on the day of the party and how to present it to the people to  get the most useful information out of it. We were aware that the participants would know in  advance of the pre-launch event - the organizers, in fact, made sure to advertise it  accordingly in the invites -, so we knew that it was an opportunity which we needed to  capitalize.  For such, we opted to focus on the fit and comfort of our first products, since we had not had  yet the possibility to receive feedback on it (whilst with the designs and prints, on the other  hand, we had already managed to gather useful information via surveys and brief  interviews). We brought to the party 1861-themed roll-ups and posters to create cozy and  recognizable stands, in which we had potential customers try different kinds of fits and  garment models of the products - the t-shirt and the hoodie - that we had decided to launch.  We had skinnier/more loose fits, a couple of different material combinations and big smiles  on our faces, so the party finally began as we waited impatiently the first people to come by  (we decided not to go and chase them out in the wild, as it was not the most effective  approach to adopt in that environment).\n",
      "\n",
      "Insight & Approach\n",
      "\n",
      "The learning launch event was a success, and really helped us also in gaining valuable  traction among friends of the potential clients by word-of-mouth, a nice side-effect to add  along! Naturally, though, our main goal was a different one as previously specified, which we\n",
      "\n",
      "managed to cover with a concrete deal of useful gathered information. For instance, we  realized that a skinnier fit for the t-shirts was welcomed, and that the 100% cotton samples  that we brought with us were preferred; for what concerns the hoodies, we realized that  some samples had too-small hoods (thus a larger, less tight on the scalp one was preferred),  fits which were looser on the trunk and tighter on the arms were more liked and finally a  mixture which was - unlike the t-shirts - not 100% cotton, rather 80% cotton and 20%  polyester gave the best combination of on-skin comfort and wearability feel. At the end of the  night we had some people approaching us to buy some of the samples, too! One extra perk  that made us even more enthusiast of the experience.\n",
      "\n",
      "After that, we proceeded with our launch campaign and sold the two models which we got  feedback on at the event. We had planned a second, four-garment launch for later that year  and were looking forward to choosing amongst the designs that we were coming up with,  when eventually other commitments entered each one of our lives and we could not properly  follow up the brand.  However, the experience enriched us on the ways in which such a tool could become useful  when approaching a problem to solve (in our case, the best possible products that we could  enter the market with), and the reality is that - albeit on different scales -, it could really be  useful in a very wide variety of scenarios! If we were, though, to proceed with the second  launch as we had planned, we would have used the same learning-launch approach for what  concerns the garments to use for our products. However, we may have wanted to extend it  to different designs on which giving our potential customers the possibility to choose from,  although the visualization approach (that we resorted to for the same task during our first  launch) revealed to be effective: having visualizations of what our products would look like  via mock-ups allows to reach a wider crowd with a less demanding organization, and to  gather important feedback on the designs based on a reliable representation of what the  finished product would look like. It is also easy to change the mock-ups on the go during  interviews in accordance to suggestions and proposals of the interviewees, so that an agile  and interactive learning process with potential customers can be instituted.\n",
      "\n",
      "\n",
      "Andreahaven\n",
      "Reflection – Learning Launch of 1861. Milano\n",
      "\n",
      "Challenge & Selection\n",
      "\n",
      "During my second-to-last year of high-school (2013), I decided to team up with two friends of  mine and explore a market which at the time was still uncharted: create a fashion brand  aimed towards the street culture and based on Milan, our hometown. If the former - the  street-culture-oriented fashion - was an upcoming trend back then which was just starting to  take off, the latter was yet to be covered and provided an interesting ground to experiment  some entrepreneurship ideas off some friends’ impressions and insights.  We thus set up all of the necessary contacts, the business model, and got ourselves an  identity (1861. Milano - 743 Erika Bypass Apt. 419\n",
      "Andreahaven, IL 54207) looking forward to our first  launch, which would simply be composed of a t-shirt and a hoodie. However, even though  we already decided on the main aspects of the product line, being at our first experience in  the field we deemed useful resorting to gather some of our potential clients’ feedback  (mostly teenagers, just like us). For this, we made use of some contacts of ours to talk to  one of the main party organizations in Milan, and found out about a date of a party which  would suit perfectly our time-constraint needs with respect to the products’ actual launch.  The organization of the party, who appeared interested in the project, granted us the  possibility of organizing stands at the event to promote an actual pre-launch event, in which  we could show and discuss samples directly with our potential clientbase: a technique which  just later - when attending this course - I realized being called “learning launch”.\n",
      "\n",
      "Application\n",
      "\n",
      "We then began to think how to organize the learning launch event, in order to understand  what we would need to bring on the day of the party and how to present it to the people to  get the most useful information out of it. We were aware that the participants would know in  advance of the pre-launch event - the organizers, in fact, made sure to advertise it  accordingly in the invites -, so we knew that it was an opportunity which we needed to  capitalize.  For such, we opted to focus on the fit and comfort of our first products, since we had not had  yet the possibility to receive feedback on it (whilst with the designs and prints, on the other  hand, we had already managed to gather useful information via surveys and brief  interviews). We brought to the party 1861-themed roll-ups and posters to create cozy and  recognizable stands, in which we had potential customers try different kinds of fits and  garment models of the products - the t-shirt and the hoodie - that we had decided to launch.  We had skinnier/more loose fits, a couple of different material combinations and big smiles  on our faces, so the party finally began as we waited impatiently the first people to come by  (we decided not to go and chase them out in the wild, as it was not the most effective  approach to adopt in that environment).\n",
      "\n",
      "Insight & Approach\n",
      "\n",
      "The learning launch event was a success, and really helped us also in gaining valuable  traction among friends of the potential clients by word-of-mouth, a nice side-effect to add  along! Naturally, though, our main goal was a different one as previously specified, which we\n",
      "\n",
      "managed to cover with a concrete deal of useful gathered information. For instance, we  realized that a skinnier fit for the t-shirts was welcomed, and that the 100% cotton samples  that we brought with us were preferred; for what concerns the hoodies, we realized that  some samples had too-small hoods (thus a larger, less tight on the scalp one was preferred),  fits which were looser on the trunk and tighter on the arms were more liked and finally a  mixture which was - unlike the t-shirts - not 100% cotton, rather 80% cotton and 20%  polyester gave the best combination of on-skin comfort and wearability feel. At the end of the  night we had some people approaching us to buy some of the samples, too! One extra perk  that made us even more enthusiast of the experience.\n",
      "\n",
      "After that, we proceeded with our launch campaign and sold the two models which we got  feedback on at the event. We had planned a second, four-garment launch for later that year  and were looking forward to choosing amongst the designs that we were coming up with,  when eventually other commitments entered each one of our lives and we could not properly  follow up the brand.  However, the experience enriched us on the ways in which such a tool could become useful  when approaching a problem to solve (in our case, the best possible products that we could  enter the market with), and the reality is that - albeit on different scales -, it could really be  useful in a very wide variety of scenarios! If we were, though, to proceed with the second  launch as we had planned, we would have used the same learning-launch approach for what  concerns the garments to use for our products. However, we may have wanted to extend it  to different designs on which giving our potential customers the possibility to choose from,  although the visualization approach (that we resorted to for the same task during our first  launch) revealed to be effective: having visualizations of what our products would look like  via mock-ups allows to reach a wider crowd with a less demanding organization, and to  gather important feedback on the designs based on a reliable representation of what the  finished product would look like. It is also easy to change the mock-ups on the go during  interviews in accordance to suggestions and proposals of the interviewees, so that an agile  and interactive learning process with potential customers can be instituted.\n",
      "\n",
      "\n",
      ",\n",
      "Reflection – Learning Launch of 1861. Milano\n",
      "\n",
      "Challenge & Selection\n",
      "\n",
      "During my second-to-last year of high-school (2013), I decided to team up with two friends of  mine and explore a market which at the time was still uncharted: create a fashion brand  aimed towards the street culture and based on Milan, our hometown. If the former - the  street-culture-oriented fashion - was an upcoming trend back then which was just starting to  take off, the latter was yet to be covered and provided an interesting ground to experiment  some entrepreneurship ideas off some friends’ impressions and insights.  We thus set up all of the necessary contacts, the business model, and got ourselves an  identity (1861. Milano - 743 Erika Bypass Apt. 419\n",
      "Andreahaven, IL 54207) looking forward to our first  launch, which would simply be composed of a t-shirt and a hoodie. However, even though  we already decided on the main aspects of the product line, being at our first experience in  the field we deemed useful resorting to gather some of our potential clients’ feedback  (mostly teenagers, just like us). For this, we made use of some contacts of ours to talk to  one of the main party organizations in Milan, and found out about a date of a party which  would suit perfectly our time-constraint needs with respect to the products’ actual launch.  The organization of the party, who appeared interested in the project, granted us the  possibility of organizing stands at the event to promote an actual pre-launch event, in which  we could show and discuss samples directly with our potential clientbase: a technique which  just later - when attending this course - I realized being called “learning launch”.\n",
      "\n",
      "Application\n",
      "\n",
      "We then began to think how to organize the learning launch event, in order to understand  what we would need to bring on the day of the party and how to present it to the people to  get the most useful information out of it. We were aware that the participants would know in  advance of the pre-launch event - the organizers, in fact, made sure to advertise it  accordingly in the invites -, so we knew that it was an opportunity which we needed to  capitalize.  For such, we opted to focus on the fit and comfort of our first products, since we had not had  yet the possibility to receive feedback on it (whilst with the designs and prints, on the other  hand, we had already managed to gather useful information via surveys and brief  interviews). We brought to the party 1861-themed roll-ups and posters to create cozy and  recognizable stands, in which we had potential customers try different kinds of fits and  garment models of the products - the t-shirt and the hoodie - that we had decided to launch.  We had skinnier/more loose fits, a couple of different material combinations and big smiles  on our faces, so the party finally began as we waited impatiently the first people to come by  (we decided not to go and chase them out in the wild, as it was not the most effective  approach to adopt in that environment).\n",
      "\n",
      "Insight & Approach\n",
      "\n",
      "The learning launch event was a success, and really helped us also in gaining valuable  traction among friends of the potential clients by word-of-mouth, a nice side-effect to add  along! Naturally, though, our main goal was a different one as previously specified, which we\n",
      "\n",
      "managed to cover with a concrete deal of useful gathered information. For instance, we  realized that a skinnier fit for the t-shirts was welcomed, and that the 100% cotton samples  that we brought with us were preferred; for what concerns the hoodies, we realized that  some samples had too-small hoods (thus a larger, less tight on the scalp one was preferred),  fits which were looser on the trunk and tighter on the arms were more liked and finally a  mixture which was - unlike the t-shirts - not 100% cotton, rather 80% cotton and 20%  polyester gave the best combination of on-skin comfort and wearability feel. At the end of the  night we had some people approaching us to buy some of the samples, too! One extra perk  that made us even more enthusiast of the experience.\n",
      "\n",
      "After that, we proceeded with our launch campaign and sold the two models which we got  feedback on at the event. We had planned a second, four-garment launch for later that year  and were looking forward to choosing amongst the designs that we were coming up with,  when eventually other commitments entered each one of our lives and we could not properly  follow up the brand.  However, the experience enriched us on the ways in which such a tool could become useful  when approaching a problem to solve (in our case, the best possible products that we could  enter the market with), and the reality is that - albeit on different scales -, it could really be  useful in a very wide variety of scenarios! If we were, though, to proceed with the second  launch as we had planned, we would have used the same learning-launch approach for what  concerns the garments to use for our products. However, we may have wanted to extend it  to different designs on which giving our potential customers the possibility to choose from,  although the visualization approach (that we resorted to for the same task during our first  launch) revealed to be effective: having visualizations of what our products would look like  via mock-ups allows to reach a wider crowd with a less demanding organization, and to  gather important feedback on the designs based on a reliable representation of what the  finished product would look like. It is also easy to change the mock-ups on the go during  interviews in accordance to suggestions and proposals of the interviewees, so that an agile  and interactive learning process with potential customers can be instituted.\n",
      "\n",
      "\n",
      "IL\n",
      "Reflection – Learning Launch of 1861. Milano\n",
      "\n",
      "Challenge & Selection\n",
      "\n",
      "During my second-to-last year of high-school (2013), I decided to team up with two friends of  mine and explore a market which at the time was still uncharted: create a fashion brand  aimed towards the street culture and based on Milan, our hometown. If the former - the  street-culture-oriented fashion - was an upcoming trend back then which was just starting to  take off, the latter was yet to be covered and provided an interesting ground to experiment  some entrepreneurship ideas off some friends’ impressions and insights.  We thus set up all of the necessary contacts, the business model, and got ourselves an  identity (1861. Milano - 743 Erika Bypass Apt. 419\n",
      "Andreahaven, IL 54207) looking forward to our first  launch, which would simply be composed of a t-shirt and a hoodie. However, even though  we already decided on the main aspects of the product line, being at our first experience in  the field we deemed useful resorting to gather some of our potential clients’ feedback  (mostly teenagers, just like us). For this, we made use of some contacts of ours to talk to  one of the main party organizations in Milan, and found out about a date of a party which  would suit perfectly our time-constraint needs with respect to the products’ actual launch.  The organization of the party, who appeared interested in the project, granted us the  possibility of organizing stands at the event to promote an actual pre-launch event, in which  we could show and discuss samples directly with our potential clientbase: a technique which  just later - when attending this course - I realized being called “learning launch”.\n",
      "\n",
      "Application\n",
      "\n",
      "We then began to think how to organize the learning launch event, in order to understand  what we would need to bring on the day of the party and how to present it to the people to  get the most useful information out of it. We were aware that the participants would know in  advance of the pre-launch event - the organizers, in fact, made sure to advertise it  accordingly in the invites -, so we knew that it was an opportunity which we needed to  capitalize.  For such, we opted to focus on the fit and comfort of our first products, since we had not had  yet the possibility to receive feedback on it (whilst with the designs and prints, on the other  hand, we had already managed to gather useful information via surveys and brief  interviews). We brought to the party 1861-themed roll-ups and posters to create cozy and  recognizable stands, in which we had potential customers try different kinds of fits and  garment models of the products - the t-shirt and the hoodie - that we had decided to launch.  We had skinnier/more loose fits, a couple of different material combinations and big smiles  on our faces, so the party finally began as we waited impatiently the first people to come by  (we decided not to go and chase them out in the wild, as it was not the most effective  approach to adopt in that environment).\n",
      "\n",
      "Insight & Approach\n",
      "\n",
      "The learning launch event was a success, and really helped us also in gaining valuable  traction among friends of the potential clients by word-of-mouth, a nice side-effect to add  along! Naturally, though, our main goal was a different one as previously specified, which we\n",
      "\n",
      "managed to cover with a concrete deal of useful gathered information. For instance, we  realized that a skinnier fit for the t-shirts was welcomed, and that the 100% cotton samples  that we brought with us were preferred; for what concerns the hoodies, we realized that  some samples had too-small hoods (thus a larger, less tight on the scalp one was preferred),  fits which were looser on the trunk and tighter on the arms were more liked and finally a  mixture which was - unlike the t-shirts - not 100% cotton, rather 80% cotton and 20%  polyester gave the best combination of on-skin comfort and wearability feel. At the end of the  night we had some people approaching us to buy some of the samples, too! One extra perk  that made us even more enthusiast of the experience.\n",
      "\n",
      "After that, we proceeded with our launch campaign and sold the two models which we got  feedback on at the event. We had planned a second, four-garment launch for later that year  and were looking forward to choosing amongst the designs that we were coming up with,  when eventually other commitments entered each one of our lives and we could not properly  follow up the brand.  However, the experience enriched us on the ways in which such a tool could become useful  when approaching a problem to solve (in our case, the best possible products that we could  enter the market with), and the reality is that - albeit on different scales -, it could really be  useful in a very wide variety of scenarios! If we were, though, to proceed with the second  launch as we had planned, we would have used the same learning-launch approach for what  concerns the garments to use for our products. However, we may have wanted to extend it  to different designs on which giving our potential customers the possibility to choose from,  although the visualization approach (that we resorted to for the same task during our first  launch) revealed to be effective: having visualizations of what our products would look like  via mock-ups allows to reach a wider crowd with a less demanding organization, and to  gather important feedback on the designs based on a reliable representation of what the  finished product would look like. It is also easy to change the mock-ups on the go during  interviews in accordance to suggestions and proposals of the interviewees, so that an agile  and interactive learning process with potential customers can be instituted.\n",
      "\n",
      "\n",
      "54207\n"
     ]
    }
   ],
   "source": [
    "def print_labels_examples(input_label, start=0, finish=10):\n",
    "    count = 0\n",
    "    for doc in data:\n",
    "        for token, label in zip(doc['tokens'], doc['labels']):\n",
    "            if label == input_label:\n",
    "                if start <= count <= finish:\n",
    "                    print(doc['full_text'])\n",
    "                    print(token)\n",
    "                elif count > finish:\n",
    "                    return\n",
    "                count += 1\n",
    "print_labels_examples('I-STREET_ADDRESS', 0, 1000)\n",
    "# print_labels_examples('I-URL_PERSONAL')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T15:28:10.970459600Z",
     "start_time": "2024-02-11T15:28:10.876449900Z"
    }
   },
   "id": "332a51845def8c13",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_of_tokens = sum([len(doc['tokens']) for doc in data])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:27:11.326739700Z",
     "start_time": "2024-02-11T16:27:11.317718700Z"
    }
   },
   "id": "baee4dde4596fd25",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "possible_labels = ['O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'B-URL_PERSONAL', 'B-ID_NUM',\n",
    "                        'B-EMAIL', 'I-STREET_ADDRESS', 'I-PHONE_NUM', 'B-USERNAME', 'B-PHONE_NUM',\n",
    "                        'B-STREET_ADDRESS', 'I-URL_PERSONAL', 'I-ID_NUM']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:27:12.095117400Z",
     "start_time": "2024-02-11T16:27:12.083157300Z"
    }
   },
   "id": "fd6de8b41203ffee",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 148/6807 [03:37<2:43:13,  1.47s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [46]\u001B[0m, in \u001B[0;36m<cell line: 15>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     16\u001B[0m prediction[doc[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m'\u001B[39m]] \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m label, token \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(doc[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m], doc[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtokens\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m---> 18\u001B[0m     curr_prediction \u001B[38;5;241m=\u001B[39m \u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwas_first_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m curr_prediction \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mB-NAME_STUDENT\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     20\u001B[0m         was_first_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "Input \u001B[1;32mIn [44]\u001B[0m, in \u001B[0;36mpredict\u001B[1;34m(input_token, was_first_name)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(input_token, was_first_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# if is_email(input_token):\u001B[39;00m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;66;03m#     return 'B-EMAIL'\u001B[39;00m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;66;03m# if is_url(input_token):\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m#     return 'B-URL_PERSONAL'\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m     naming \u001B[38;5;241m=\u001B[39m \u001B[43mis_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_token\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwas_first_name\u001B[49m\u001B[43m)\u001B[49m \n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m naming \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m      8\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m naming\n",
      "Input \u001B[1;32mIn [45]\u001B[0m, in \u001B[0;36mis_name\u001B[1;34m(input_token, was_first_name)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_name\u001B[39m(input_token, was_first_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m input_token[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39misupper() \u001B[38;5;129;01mand\u001B[39;00m input_token \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIt\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThis\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mI\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m----> 3\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_ner\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_token\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m      4\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m was_first_name:\n\u001B[0;32m      5\u001B[0m                 \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mI-NAME_STUDENT\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\Studies\\TAU\\Year4\\workshop\\PII-Detection\\pii_detection\\LLM.py:65\u001B[0m, in \u001B[0;36mLlmModel.query_ner\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mquery_ner\u001B[39m(\u001B[38;5;28mself\u001B[39m, text):\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:192\u001B[0m, in \u001B[0;36mTokenClassificationPipeline.__call__\u001B[1;34m(self, inputs, **kwargs)\u001B[0m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m offset_mapping:\n\u001B[0;32m    190\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moffset_mapping\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m offset_mapping\n\u001B[1;32m--> 192\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1074\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1072\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001B[0;32m   1073\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1074\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1081\u001B[0m, in \u001B[0;36mPipeline.run_single\u001B[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[0m\n\u001B[0;32m   1079\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[0;32m   1080\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpreprocess_params)\n\u001B[1;32m-> 1081\u001B[0m     model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(model_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mforward_params)\n\u001B[0;32m   1082\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(model_outputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpostprocess_params)\n\u001B[0;32m   1083\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:990\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[1;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[0;32m    988\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[0;32m    989\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m--> 990\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward(model_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mforward_params)\n\u001B[0;32m    991\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m    992\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:218\u001B[0m, in \u001B[0;36mTokenClassificationPipeline._forward\u001B[1;34m(self, model_inputs)\u001B[0m\n\u001B[0;32m    216\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(model_inputs\u001B[38;5;241m.\u001B[39mdata)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 218\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_inputs)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m    221\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogits\u001B[39m\u001B[38;5;124m\"\u001B[39m: logits,\n\u001B[0;32m    222\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspecial_tokens_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m: special_tokens_mask,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    225\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_inputs,\n\u001B[0;32m    226\u001B[0m }\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1751\u001B[0m, in \u001B[0;36mBertForTokenClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001B[39;00m\n\u001B[0;32m   1748\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1749\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1751\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1752\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1753\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1754\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1755\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1756\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1757\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1758\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1759\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1760\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1761\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1763\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1765\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(sequence_output)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1014\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1005\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m   1007\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[0;32m   1008\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m   1009\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1012\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[0;32m   1013\u001B[0m )\n\u001B[1;32m-> 1014\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1015\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1016\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1017\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1018\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1019\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1020\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1021\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1022\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1023\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1024\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1025\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1026\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1027\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:603\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    594\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[0;32m    595\u001B[0m         create_custom_forward(layer_module),\n\u001B[0;32m    596\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    600\u001B[0m         encoder_attention_mask,\n\u001B[0;32m    601\u001B[0m     )\n\u001B[0;32m    602\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 603\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    604\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    605\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    606\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    607\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    608\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    609\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    610\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    611\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    613\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    614\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:531\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    528\u001B[0m     cross_attn_present_key_value \u001B[38;5;241m=\u001B[39m cross_attention_outputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    529\u001B[0m     present_key_value \u001B[38;5;241m=\u001B[39m present_key_value \u001B[38;5;241m+\u001B[39m cross_attn_present_key_value\n\u001B[1;32m--> 531\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m \u001B[43mapply_chunking_to_forward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    532\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeed_forward_chunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchunk_size_feed_forward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseq_len_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_output\u001B[49m\n\u001B[0;32m    533\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    534\u001B[0m outputs \u001B[38;5;241m=\u001B[39m (layer_output,) \u001B[38;5;241m+\u001B[39m outputs\n\u001B[0;32m    536\u001B[0m \u001B[38;5;66;03m# if decoder, return the attn key/values as the last output\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\pytorch_utils.py:246\u001B[0m, in \u001B[0;36mapply_chunking_to_forward\u001B[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001B[0m\n\u001B[0;32m    243\u001B[0m     \u001B[38;5;66;03m# concatenate output at same dimension\u001B[39;00m\n\u001B[0;32m    244\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(output_chunks, dim\u001B[38;5;241m=\u001B[39mchunk_dim)\n\u001B[1;32m--> 246\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_tensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:543\u001B[0m, in \u001B[0;36mBertLayer.feed_forward_chunk\u001B[1;34m(self, attention_output)\u001B[0m\n\u001B[0;32m    542\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfeed_forward_chunk\u001B[39m(\u001B[38;5;28mself\u001B[39m, attention_output):\n\u001B[1;32m--> 543\u001B[0m     intermediate_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mintermediate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattention_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    544\u001B[0m     layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(intermediate_output, attention_output)\n\u001B[0;32m    545\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m layer_output\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:443\u001B[0m, in \u001B[0;36mBertIntermediate.forward\u001B[1;34m(self, hidden_states)\u001B[0m\n\u001B[0;32m    442\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m--> 443\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdense\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    444\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate_act_fn(hidden_states)\n\u001B[0;32m    445\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m hidden_states\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "TP = {}\n",
    "FP = {}\n",
    "FN = {}\n",
    "y_true = []\n",
    "y_pred = []\n",
    "index = 1\n",
    "detected_urls_enumerate = []\n",
    "detected_urls = []\n",
    "for classification_type in possible_labels:\n",
    "    TP[classification_type] = 0\n",
    "    FP[classification_type] = 0\n",
    "    FN[classification_type] = 0\n",
    "prediction = {}\n",
    "was_first_name = False\n",
    "for doc in tqdm(data):\n",
    "    prediction[doc['document']] = []\n",
    "    for label, token in zip(doc['labels'], doc['tokens']):\n",
    "        curr_prediction = predict(token, was_first_name)\n",
    "        if curr_prediction == 'B-NAME_STUDENT':\n",
    "            was_first_name = True\n",
    "        else:\n",
    "            was_first_name = False\n",
    "        y_true.append(label)\n",
    "        y_pred.append(curr_prediction)\n",
    "        prediction[doc['document']].append(curr_prediction)\n",
    "        if curr_prediction == label:\n",
    "            TP[curr_prediction] += 1\n",
    "        else:\n",
    "            FP[curr_prediction] += 1\n",
    "            FN[label] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:36:16.569982Z",
     "start_time": "2024-02-11T16:32:38.716984Z"
    }
   },
   "id": "7cdacddbf33fe949",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# urls_prompt = LLM.LlmModel.get_prompt_to_personal_url(detected_urls)\n",
    "# response = llm.query_llm(urls_prompt)\n",
    "# response.split('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T15:19:12.177020900Z",
     "start_time": "2024-02-11T15:18:35.913250500Z"
    }
   },
   "id": "cbb4d1bf773cc0c0",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For label O: Recall: 0.9999785562289746, Precision: 0.9994727901001519\n",
      "For label B-NAME_STUDENT: Recall: 0.0, Precision: 0\n",
      "For label I-NAME_STUDENT: Recall: 0.0, Precision: 0\n",
      "For label B-URL_PERSONAL: Recall: 0.9727272727272728, Precision: 0.5\n",
      "For label B-ID_NUM: Recall: 0.0, Precision: 0\n",
      "For label B-EMAIL: Recall: 0.0, Precision: 0\n",
      "For label I-STREET_ADDRESS: Recall: 0.0, Precision: 0\n",
      "For label I-PHONE_NUM: Recall: 0.0, Precision: 0\n",
      "For label B-USERNAME: Recall: 0.0, Precision: 0\n",
      "For label B-PHONE_NUM: Recall: 0.0, Precision: 0\n",
      "For label B-STREET_ADDRESS: Recall: 0.0, Precision: 0\n",
      "For label I-URL_PERSONAL: Recall: 0.0, Precision: 0\n",
      "For label I-ID_NUM: Recall: 0.0, Precision: 0\n",
      "final score:  0.9994513806919252\n"
     ]
    }
   ],
   "source": [
    "recalls = []\n",
    "precisions = []\n",
    "for label in possible_labels:\n",
    "    precision = 0 if TP[label] == 0 else TP[label] / (TP[label] + FP[label])\n",
    "    recall = TP[label] / (TP[label] + FN[label])\n",
    "    print(\"For label {}: Recall: {}, Precision: {}\".format(label, recall, precision))\n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T15:49:01.717911700Z",
     "start_time": "2024-02-11T15:48:42.211711500Z"
    }
   },
   "id": "a243129672557b97",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"final score: \", fbeta_score(y_true, y_pred, average='micro', beta=5))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ea2a4aa27b570c8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7faf8eeb82e632a5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1275c0b6d6d991cf"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silvia Villalobos\n",
      "\n",
      "Challenge:\n",
      "\n",
      "There is a company which provides financial advisory to customers either in person or virtual.  Lately organisation climate has been seen decayed as result of arguments, hassles and the  lack of fraternity and cooperation among the campaign workers. The aim is improving  climate organisation to transmit unity and trust to our customer.\n",
      "\n",
      "Selection:\n",
      "\n",
      "Storytelling is the first tool selected, because this tool allows to connect with the audience,  to make understandable the message, and to transmit emotions. Campaign workers would  feel identified and understand the importance of tolerance and empathy.\n",
      "\n",
      "Application and insight:\n",
      "\n",
      "Many stories were told in various sections. Stories from previous experiences, fictional  stories, and stories told by participants created a different atmosphere due to participants  started to produce deeper relationships among them and recognize the importance of being  empathic. An important result was that meeting with clients were longer.\n",
      "\n",
      "Approach:\n",
      "\n",
      "The activities work in a good way, but visualization tool would work very well in a challenge  like this. Showing the way, some elements to get a harmonious atmosphere through  visualization is an option in a further situation.\n"
     ]
    }
   ],
   "source": [
    "print(data[6]['full_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:06:27.319019500Z",
     "start_time": "2024-02-11T16:06:27.285130700Z"
    }
   },
   "id": "553a4673815f397f",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[{'entity': 'B-ORG', 'score': 0.8830654, 'index': 1, 'word': 'Start', 'start': 0, 'end': 5}]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[{'entity': 'B-ORG', 'score': 0.88072574, 'index': 1, 'word': 'El', 'start': 0, 'end': 2}]\n",
      "[{'entity': 'B-PER', 'score': 0.46941844, 'index': 1, 'word': 'Am', 'start': 0, 'end': 2}]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[{'entity': 'B-ORG', 'score': 0.9995167, 'index': 1, 'word': 'Barcelona', 'start': 0, 'end': 9}]\n",
      "[]\n",
      "[{'entity': 'B-LOC', 'score': 0.99982965, 'index': 1, 'word': 'Spain', 'start': 0, 'end': 5}]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[{'entity': 'B-LOC', 'score': 0.929586, 'index': 1, 'word': 'P', 'start': 0, 'end': 1}, {'entity': 'B-LOC', 'score': 0.84071195, 'index': 2, 'word': '##yre', 'start': 1, 'end': 4}, {'entity': 'I-LOC', 'score': 0.7833575, 'index': 3, 'word': '##nees', 'start': 4, 'end': 8}]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for token in data[5]['tokens']:\n",
    "    print(llm.query_ner(token))    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:04:23.996434900Z",
     "start_time": "2024-02-11T16:04:12.790269900Z"
    }
   },
   "id": "f1e0c0c26699079a",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'entity': 'B-PER',\n  'score': 0.48807332,\n  'index': 1,\n  'word': 'Si',\n  'start': 0,\n  'end': 2},\n {'entity': 'I-PER',\n  'score': 0.94796073,\n  'index': 4,\n  'word': 'Villa',\n  'start': 7,\n  'end': 12},\n {'entity': 'I-ORG',\n  'score': 0.70209837,\n  'index': 5,\n  'word': '##lo',\n  'start': 12,\n  'end': 14},\n {'entity': 'I-ORG',\n  'score': 0.7002141,\n  'index': 6,\n  'word': '##bos',\n  'start': 14,\n  'end': 17}]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.query_ner(data[6]['full_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:06:56.669175600Z",
     "start_time": "2024-02-11T16:06:56.442706100Z"
    }
   },
   "id": "3bdc45a07831b015",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avril\n",
      "Nathalie\n",
      "Sylla\n",
      "Buzan\n",
      "T.\n",
      "Buzan\n",
      "B.\n",
      "Dessine\n",
      "Paris\n",
      "Les\n",
      "Éditions\n",
      "Avril\n",
      "Nathalie\n",
      "Sylla\n",
      "Avril\n",
      "Nathalie\n",
      "Sylla\n",
      "Mind\n",
      "Diego\n",
      "Estrada\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [22]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m doc[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtokens\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m token[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39misupper():\n\u001B[1;32m----> 4\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_ner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m      5\u001B[0m             \u001B[38;5;28mprint\u001B[39m(token)\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\Studies\\TAU\\Year4\\workshop\\PII-Detection\\pii_detection\\LLM.py:65\u001B[0m, in \u001B[0;36mLlmModel.query_ner\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mquery_ner\u001B[39m(\u001B[38;5;28mself\u001B[39m, text):\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:192\u001B[0m, in \u001B[0;36mTokenClassificationPipeline.__call__\u001B[1;34m(self, inputs, **kwargs)\u001B[0m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m offset_mapping:\n\u001B[0;32m    190\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moffset_mapping\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m offset_mapping\n\u001B[1;32m--> 192\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1074\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1072\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001B[0;32m   1073\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1074\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1081\u001B[0m, in \u001B[0;36mPipeline.run_single\u001B[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[0m\n\u001B[0;32m   1079\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[0;32m   1080\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpreprocess_params)\n\u001B[1;32m-> 1081\u001B[0m     model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(model_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mforward_params)\n\u001B[0;32m   1082\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(model_outputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpostprocess_params)\n\u001B[0;32m   1083\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:990\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[1;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[0;32m    988\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[0;32m    989\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m--> 990\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward(model_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mforward_params)\n\u001B[0;32m    991\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m    992\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:218\u001B[0m, in \u001B[0;36mTokenClassificationPipeline._forward\u001B[1;34m(self, model_inputs)\u001B[0m\n\u001B[0;32m    216\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(model_inputs\u001B[38;5;241m.\u001B[39mdata)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 218\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_inputs)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m    221\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogits\u001B[39m\u001B[38;5;124m\"\u001B[39m: logits,\n\u001B[0;32m    222\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspecial_tokens_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m: special_tokens_mask,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    225\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_inputs,\n\u001B[0;32m    226\u001B[0m }\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1751\u001B[0m, in \u001B[0;36mBertForTokenClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001B[39;00m\n\u001B[0;32m   1748\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1749\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1751\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1752\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1753\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1754\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1755\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1756\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1757\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1758\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1759\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1760\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1761\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1763\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1765\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(sequence_output)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1014\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1005\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m   1007\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[0;32m   1008\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[0;32m   1009\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1012\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[0;32m   1013\u001B[0m )\n\u001B[1;32m-> 1014\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1015\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1016\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1017\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1018\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1019\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1020\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1021\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1022\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1023\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1024\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1025\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1026\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1027\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:603\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    594\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[0;32m    595\u001B[0m         create_custom_forward(layer_module),\n\u001B[0;32m    596\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    600\u001B[0m         encoder_attention_mask,\n\u001B[0;32m    601\u001B[0m     )\n\u001B[0;32m    602\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 603\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    604\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    605\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    606\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    607\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    608\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    609\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    610\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    611\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    613\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    614\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:489\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    479\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    486\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[0;32m    487\u001B[0m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[0;32m    488\u001B[0m     self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 489\u001B[0m     self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    496\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    498\u001B[0m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:419\u001B[0m, in \u001B[0;36mBertAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    409\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    410\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    411\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    417\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    418\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m--> 419\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    420\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    421\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    422\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    423\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    424\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    425\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    427\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    428\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(self_outputs[\u001B[38;5;241m0\u001B[39m], hidden_states)\n\u001B[0;32m    429\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attention_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:359\u001B[0m, in \u001B[0;36mBertSelfAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    355\u001B[0m     attention_probs \u001B[38;5;241m=\u001B[39m attention_probs \u001B[38;5;241m*\u001B[39m head_mask\n\u001B[0;32m    357\u001B[0m context_layer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmatmul(attention_probs, value_layer)\n\u001B[1;32m--> 359\u001B[0m context_layer \u001B[38;5;241m=\u001B[39m \u001B[43mcontext_layer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpermute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[0;32m    360\u001B[0m new_context_layer_shape \u001B[38;5;241m=\u001B[39m context_layer\u001B[38;5;241m.\u001B[39msize()[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m+\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mall_head_size,)\n\u001B[0;32m    361\u001B[0m context_layer \u001B[38;5;241m=\u001B[39m context_layer\u001B[38;5;241m.\u001B[39mview(new_context_layer_shape)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for doc in data:\n",
    "    for token in doc['tokens']:\n",
    "        if token[0].isupper():\n",
    "            if llm.query_ner(token):\n",
    "                print(token)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T16:17:27.208826400Z",
     "start_time": "2024-02-11T16:17:24.602340900Z"
    }
   },
   "id": "a5c6ecc51efc0ac9",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8b375a4c87d6df34"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1206fd819a1da172"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1e17c52c6f67d188"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "caa0e142ce62138"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "72031eb77c229804"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4511ac01e60f3dbb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c243a68c17d22e14"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cdda74707ac4556d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e1dd58e174795370"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "93174a645467819f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pii_detection.data_split_utils import shuffle_and_split\n",
    "train, val, test = shuffle_and_split(data, save_dir=\"../data\")\n",
    "\n",
    "# read data/val.json\n",
    "for name in [\"train\", \"val\", \"test\"]:\n",
    "    with open(f\"../data/{name}_shard.json\", \"r\") as f:\n",
    "        dataset = json.load(f)\n",
    "    assert dataset == locals()[name]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:34:55.222630700Z",
     "start_time": "2024-02-06T08:34:46.698717400Z"
    }
   },
   "id": "f02e1b69e88bea3a",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "4764\n",
      "dict_keys(['document', 'full_text', 'tokens', 'trailing_whitespace', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "print(type(train))\n",
    "print(len(train))\n",
    "print(train[1].keys())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:34:55.238578100Z",
     "start_time": "2024-02-06T08:34:55.222630700Z"
    }
   },
   "id": "cf4b31c228ffce25",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reflection – Learning Launch\n",
      "\n",
      "Paola Garcia\n",
      "\n",
      "Challenge\n",
      "\n",
      "In the financial services industry, the strategies developed to manage lending portfolios are developed  through data analysis of past performance.  In the collections environment, analytics and traditional  methods to contact customers (phone, letters and email) are the norm.  As the number of missed  payments on an account increases, the ability to reach customers decreases.   The result is higher  delinquency rates, increase expense and customer complaints.\n",
      "\n",
      "A project was launched to determine how these measures could be improved.  A small team was formed  which included people from various departments including Analytics, Operations, Finance, Marketing to  name a few.   A recommendation was made to utilize design thinking.  Working with our Marketing  Research team several tools were utilized to understand our customer needs and develop some ideas to  test.  To address the needs of a specific persona, Customers who felt uncomfortable discussing their  situation and felt the people they spoke to on the phone lacked empathy, the idea of a collections  website was developed.\n",
      "\n",
      "Selection\n",
      "\n",
      "The team chose the learning launch to test a collections website.   The learning launch allows for a fast  and inexpensive way to run an experiment to learn.   This was facilitated by the ability to utilize an  outsourced model.  The website functionality was already developed by a vendor and provided the  minimum viable product which met the design criteria.     The learning launch provided the data needed  to determine whether the idea was good or bad.\n",
      "\n",
      "Application\n",
      "\n",
      "The team developed a detailed plan to launch the experiment including customer segments,  communication methods, measurements, and customer feedback surveys.  The website launched on  time and tested for 90 days.   The results provided significant data that the idea worked as well as new  insights to improve the website and other internal processes.\n",
      "\n",
      "Insight\n",
      "\n",
      "The learning launch enabled the team to develop and test quickly where there was not past data and  could potentially be a better approach that the traditional methods used.  In addition, it provided a lot  of customer feedback that changed the existing strategies (phone, letters, email) and enhancements to  the company website.  Ongoing use of the website has Increased  collection rates and decreased   expenses and complaints.\n",
      "\n",
      "Approach\n",
      "\n",
      "The learning launch was the best approach since we had the ability to launch quickly.  Had there not  been an existing vendor with the necessary tool, another approach would have been necessary as  prioritization of technology builds can often take significant time.\n"
     ]
    }
   ],
   "source": [
    "print(train[1]['full_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:34:55.276453800Z",
     "start_time": "2024-02-06T08:34:55.240572200Z"
    }
   },
   "id": "ea57ebce73ca4df9",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "6\n",
      "8\n",
      "13\n",
      "15\n",
      "18\n",
      "24\n",
      "30\n",
      "32\n",
      "41\n",
      "50\n",
      "51\n",
      "53\n",
      "54\n",
      "69\n",
      "83\n",
      "95\n",
      "110\n",
      "125\n",
      "129\n",
      "142\n",
      "143\n",
      "145\n",
      "154\n",
      "155\n",
      "158\n",
      "166\n",
      "206\n",
      "220\n",
      "221\n",
      "229\n",
      "236\n",
      "240\n",
      "241\n",
      "251\n",
      "253\n",
      "286\n",
      "298\n",
      "315\n",
      "321\n",
      "330\n",
      "333\n",
      "336\n",
      "354\n",
      "356\n",
      "362\n",
      "368\n",
      "374\n",
      "377\n",
      "390\n",
      "404\n",
      "405\n",
      "409\n",
      "411\n",
      "421\n",
      "429\n",
      "431\n",
      "454\n",
      "460\n",
      "465\n",
      "473\n",
      "480\n",
      "488\n",
      "495\n",
      "501\n",
      "517\n",
      "519\n",
      "526\n",
      "528\n",
      "529\n",
      "530\n",
      "533\n",
      "541\n",
      "555\n",
      "562\n",
      "566\n",
      "570\n",
      "571\n",
      "579\n",
      "582\n",
      "583\n",
      "599\n",
      "601\n",
      "606\n",
      "610\n",
      "628\n",
      "632\n",
      "635\n",
      "636\n",
      "643\n",
      "647\n",
      "658\n",
      "659\n",
      "666\n",
      "667\n",
      "669\n",
      "680\n",
      "681\n",
      "688\n",
      "691\n",
      "707\n",
      "709\n",
      "712\n",
      "713\n",
      "717\n",
      "724\n",
      "726\n",
      "735\n",
      "747\n",
      "752\n",
      "760\n",
      "764\n",
      "767\n",
      "775\n",
      "800\n",
      "805\n",
      "807\n",
      "814\n",
      "817\n",
      "821\n",
      "846\n",
      "857\n",
      "861\n",
      "863\n",
      "864\n",
      "870\n",
      "888\n",
      "893\n",
      "896\n",
      "901\n",
      "919\n",
      "921\n",
      "926\n",
      "931\n",
      "933\n",
      "939\n",
      "958\n",
      "962\n",
      "965\n",
      "966\n",
      "970\n",
      "978\n",
      "992\n",
      "1010\n",
      "1011\n",
      "1016\n",
      "1019\n",
      "1029\n",
      "1040\n",
      "1043\n",
      "1045\n",
      "1047\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1061\n",
      "1070\n",
      "1082\n",
      "1092\n",
      "1093\n",
      "1104\n",
      "1108\n",
      "1118\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1132\n",
      "1134\n",
      "1136\n",
      "1144\n",
      "1155\n",
      "1170\n",
      "1172\n",
      "1173\n",
      "1183\n",
      "1184\n",
      "1193\n",
      "1213\n",
      "1215\n",
      "1248\n",
      "1251\n",
      "1252\n",
      "1256\n",
      "1258\n",
      "1272\n",
      "1274\n",
      "1278\n",
      "1292\n",
      "1298\n",
      "1299\n",
      "1315\n",
      "1316\n",
      "1326\n",
      "1334\n",
      "1342\n",
      "1346\n",
      "1358\n",
      "1359\n",
      "1364\n",
      "1374\n",
      "1381\n",
      "1384\n",
      "1388\n",
      "1405\n",
      "1410\n",
      "1411\n",
      "1414\n",
      "1418\n",
      "1419\n",
      "1429\n",
      "1438\n",
      "1452\n",
      "1460\n",
      "1465\n",
      "1466\n",
      "1468\n",
      "1470\n",
      "1473\n",
      "1497\n",
      "1515\n",
      "1516\n",
      "1535\n",
      "1538\n",
      "1558\n",
      "1560\n",
      "1561\n",
      "1573\n",
      "1593\n",
      "1600\n",
      "1609\n",
      "1612\n",
      "1615\n",
      "1628\n",
      "1640\n",
      "1649\n",
      "1658\n",
      "1659\n",
      "1669\n",
      "1689\n",
      "1699\n",
      "1702\n",
      "1705\n",
      "1710\n",
      "1743\n",
      "1744\n",
      "1746\n",
      "1750\n",
      "1755\n",
      "1761\n",
      "1770\n",
      "1778\n",
      "1781\n",
      "1784\n",
      "1789\n",
      "1798\n",
      "1804\n",
      "1815\n",
      "1824\n",
      "1830\n",
      "1838\n",
      "1847\n",
      "1855\n",
      "1858\n",
      "1867\n",
      "1874\n",
      "1876\n",
      "1879\n",
      "1881\n",
      "1898\n",
      "1916\n",
      "1919\n",
      "1926\n",
      "1930\n",
      "1947\n",
      "1966\n",
      "1972\n",
      "1988\n",
      "1990\n",
      "1992\n",
      "1996\n",
      "2011\n",
      "2015\n",
      "2024\n",
      "2026\n",
      "2032\n",
      "2049\n",
      "2050\n",
      "2063\n",
      "2066\n",
      "2081\n",
      "2089\n",
      "2092\n",
      "2118\n",
      "2146\n",
      "2148\n",
      "2152\n",
      "2159\n",
      "2163\n",
      "2165\n",
      "2172\n",
      "2190\n",
      "2191\n",
      "2230\n",
      "2233\n",
      "2253\n",
      "2277\n",
      "2295\n",
      "2297\n",
      "2301\n",
      "2303\n",
      "2306\n",
      "2310\n",
      "2314\n",
      "2315\n",
      "2331\n",
      "2363\n",
      "2364\n",
      "2366\n",
      "2376\n",
      "2382\n",
      "2390\n",
      "2405\n",
      "2412\n",
      "2416\n",
      "2425\n",
      "2434\n",
      "2435\n",
      "2447\n",
      "2461\n",
      "2466\n",
      "2475\n",
      "2476\n",
      "2485\n",
      "2489\n",
      "2499\n",
      "2501\n",
      "2510\n",
      "2527\n",
      "2529\n",
      "2531\n",
      "2539\n",
      "2541\n",
      "2546\n",
      "2567\n",
      "2575\n",
      "2576\n",
      "2585\n",
      "2600\n",
      "2602\n",
      "2607\n",
      "2610\n",
      "2611\n",
      "2615\n",
      "2619\n",
      "2627\n",
      "2636\n",
      "2639\n",
      "2646\n",
      "2647\n",
      "2652\n",
      "2655\n",
      "2672\n",
      "2673\n",
      "2678\n",
      "2687\n",
      "2688\n",
      "2690\n",
      "2700\n",
      "2703\n",
      "2704\n",
      "2708\n",
      "2709\n",
      "2714\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2739\n",
      "2743\n",
      "2747\n",
      "2758\n",
      "2763\n",
      "2766\n",
      "2769\n",
      "2770\n",
      "2772\n",
      "2774\n",
      "2788\n",
      "2800\n",
      "2818\n",
      "2828\n",
      "2834\n",
      "2847\n",
      "2855\n",
      "2861\n",
      "2882\n",
      "2899\n",
      "2940\n",
      "2947\n",
      "2950\n",
      "2951\n",
      "2958\n",
      "2978\n",
      "2984\n",
      "2990\n",
      "2997\n",
      "2999\n",
      "3014\n",
      "3020\n",
      "3021\n",
      "3033\n",
      "3037\n",
      "3043\n",
      "3050\n",
      "3057\n",
      "3064\n",
      "3065\n",
      "3100\n",
      "3106\n",
      "3132\n",
      "3158\n",
      "3162\n",
      "3173\n",
      "3177\n",
      "3195\n",
      "3200\n",
      "3204\n",
      "3215\n",
      "3228\n",
      "3229\n",
      "3234\n",
      "3235\n",
      "3238\n",
      "3241\n",
      "3246\n",
      "3253\n",
      "3258\n",
      "3263\n",
      "3269\n",
      "3279\n",
      "3293\n",
      "3313\n",
      "3327\n",
      "3331\n",
      "3332\n",
      "3344\n",
      "3372\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3383\n",
      "3384\n",
      "3409\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3430\n",
      "3433\n",
      "3442\n",
      "3478\n",
      "3521\n",
      "3523\n",
      "3533\n",
      "3534\n",
      "3535\n",
      "3539\n",
      "3549\n",
      "3552\n",
      "3560\n",
      "3563\n",
      "3566\n",
      "3586\n",
      "3606\n",
      "3608\n",
      "3615\n",
      "3618\n",
      "3620\n",
      "3629\n",
      "3641\n",
      "3651\n",
      "3654\n",
      "3658\n",
      "3671\n",
      "3682\n",
      "3683\n",
      "3686\n",
      "3691\n",
      "3694\n",
      "3695\n",
      "3715\n",
      "3734\n",
      "3738\n",
      "3746\n",
      "3749\n",
      "3759\n",
      "3762\n",
      "3783\n",
      "3796\n",
      "3800\n",
      "3805\n",
      "3813\n",
      "3819\n",
      "3824\n",
      "3826\n",
      "3839\n",
      "3844\n",
      "3846\n",
      "3847\n",
      "3854\n",
      "3869\n",
      "3871\n",
      "3875\n",
      "3884\n",
      "3885\n",
      "3901\n",
      "3935\n",
      "3949\n",
      "3962\n",
      "3975\n",
      "3978\n",
      "3996\n",
      "3998\n",
      "4000\n",
      "4016\n",
      "4021\n",
      "4027\n",
      "4043\n",
      "4050\n",
      "4054\n",
      "4063\n",
      "4069\n",
      "4075\n",
      "4078\n",
      "4094\n",
      "4099\n",
      "4108\n",
      "4117\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4152\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4190\n",
      "4193\n",
      "4195\n",
      "4199\n",
      "4206\n",
      "4211\n",
      "4236\n",
      "4250\n",
      "4253\n",
      "4264\n",
      "4267\n",
      "4271\n",
      "4275\n",
      "4281\n",
      "4286\n",
      "4291\n",
      "4322\n",
      "4323\n",
      "4324\n",
      "4335\n",
      "4338\n",
      "4342\n",
      "4349\n",
      "4352\n",
      "4358\n",
      "4364\n",
      "4365\n",
      "4369\n",
      "4373\n",
      "4381\n",
      "4383\n",
      "4397\n",
      "4416\n",
      "4417\n",
      "4435\n",
      "4441\n",
      "4442\n",
      "4443\n",
      "4447\n",
      "4448\n",
      "4455\n",
      "4456\n",
      "4470\n",
      "4478\n",
      "4483\n",
      "4503\n",
      "4505\n",
      "4508\n",
      "4510\n",
      "4514\n",
      "4517\n",
      "4551\n",
      "4560\n",
      "4574\n",
      "4582\n",
      "4599\n",
      "4601\n",
      "4613\n",
      "4623\n",
      "4626\n",
      "4640\n",
      "4641\n",
      "4659\n",
      "4662\n",
      "4671\n",
      "4672\n",
      "4674\n",
      "4675\n",
      "4678\n",
      "4684\n",
      "4708\n",
      "4736\n",
      "4750\n",
      "4752\n",
      "4756\n",
      "4757\n",
      "4760\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train)):\n",
    "    if 'B-NAME_STUDENT' in train[i]['labels']:\n",
    "        print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:34:55.316319Z",
     "start_time": "2024-02-06T08:34:55.255521500Z"
    }
   },
   "id": "61ae783c22fef764",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "236\n",
      "241\n",
      "501\n",
      "632\n",
      "658\n",
      "681\n",
      "817\n",
      "1056\n",
      "1252\n",
      "1256\n",
      "1274\n",
      "1315\n",
      "1411\n",
      "1452\n",
      "1516\n",
      "1560\n",
      "1699\n",
      "1743\n",
      "1744\n",
      "1750\n",
      "1761\n",
      "1778\n",
      "2049\n",
      "2089\n",
      "2146\n",
      "2152\n",
      "2190\n",
      "2672\n",
      "2700\n",
      "2703\n",
      "2704\n",
      "2739\n",
      "2770\n",
      "2788\n",
      "2950\n",
      "2958\n",
      "3050\n",
      "3293\n",
      "3332\n",
      "3566\n",
      "3586\n",
      "3606\n",
      "3620\n",
      "3715\n",
      "3749\n",
      "3762\n",
      "3783\n",
      "4054\n",
      "4069\n",
      "4322\n",
      "4448\n",
      "4503\n",
      "4626\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train)):\n",
    "    if 'B-NAME_STUDENT' in train[i]['labels'] and 'I-NAME_STUDENT' not in train[i]['labels']:\n",
    "        print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:34:55.364159Z",
     "start_time": "2024-02-06T08:34:55.320305800Z"
    }
   },
   "id": "8e3dcb7afad708a1",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amritpal’s Reflection – Mind Mapping\n",
      "\n",
      "Challenge  Being a member of my company’s innovation department, I was called along with my team for an urgent  meeting. Based on our latest monthly report, a big number of our newly employed engineers have  complained about an unpleasant and boring working environment; an unfortunate fact for a company  that relies on young and fresh minds to keep aiming forward. My challenge is to create an environment  in which our employees can perform and endure their daily challenges agreeably and more pleasantly.   The project scope includes our team’s department and the new employees of other departments, with a  limited period of thirty business days. We will focus on trying to uncover and pin point the effective  solutions with regard to a pleasant environment.\n",
      "\n",
      "Selection  “When I want to do something analytical, I make a list. When I’m trying to do something creative, I make  a mind-map.” David Kelley-Founder, IDEO.  With the problem already in hand, I selected the Mind-Mapping tool at this stage of my design. I believe  it illustrates the minds of our employees to finally create a common mind amongst them regarding the  reality of our challenge.      Application  Mind Mapping is great way to brainstorm. In order to turn their ideas into reality, we had to collect data  from our employees.  My colleagues and I have prepared a reunion for all the concerned members of  the company; at first, we have demanded answers from each employee on a survey that tackled their  vision of a pleasant environment. The survey contained many types of questions, some were closed,  other were open and loaded questions that required a deeper thinking; for example: 1)Would you like a  cup of coffee every few hours? (yes/no answer), 2) How are you getting on with the new system at  work? (more elaborated answer)… We had to cover many aspects, since it is pretty normal that visions  differ from one individual to another. Our next step triggered some of the right brain functions. Each  employee had to enter an empty room, and to schematically draw on a sheet of paper his idea of a  pleasant office that meets his needs; this may include adding a window, a plant, or perhaps sharing the  room with another employee. Out of those pieces of data gathered from these employees during this  ethnographic approach, we’ve created “personas”. They represented patterns, a common mind  amongst the members.     Insight  By applying the Mind Mapping tool, my team and I have gained an advanced feedback from our  employees. We communicated all that data and created personas to finally generate a design criteria  statement that our design solution must satisfy. The results came out as expected, except for few  members that decided not to cooperate and resigned.   The agreed upon personas helped us identify the many types of personalities working in our company,  such as the sociable employee, the nature lover, the quiet one, the dreamer and more. We will try our  best to meet the needs of everyone, even though they differ widely.\n",
      "\n",
      "Approach   We can’t deny that the way we handled this problem was organized and creative, it came out with a lot  of useful data that allowed us to set our pivotal point in the design thinking process. Nevertheless, since  the results weren’t matching, noting that we will still adapt the Mind Mapping tool at this stage of our  design, we could have detailed the questions furthermore in order to limit the number of personas  created at the end. Consequently, the design solution will please almost everyone.\n"
     ]
    }
   ],
   "source": [
    "doc_index = 3783\n",
    "print(train[doc_index]['full_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:41:55.738869200Z",
     "start_time": "2024-02-06T08:41:55.707973600Z"
    }
   },
   "id": "2587e6327ae6329a",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(train[doc_index]['labels'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T08:43:27.717345500Z",
     "start_time": "2024-02-06T08:43:27.711364600Z"
    }
   },
   "id": "94141c49133a256b",
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
